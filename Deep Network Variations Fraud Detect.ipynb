{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Neural network with dropouts and linear regression model to classify Fraud/Non fraud transactions with SMOTE and ADASYN to fix dataset inbalance \n",
    "\n",
    "Here we have created 2 deep network models that run on SMOTE and ADASYN generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>sin_time</th>\n",
       "      <th>cos_time</th>\n",
       "      <th>valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1659</th>\n",
       "      <td>-80.0913</td>\n",
       "      <td>40.4012</td>\n",
       "      <td>0.119415</td>\n",
       "      <td>-0.992844</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>-77.4874</td>\n",
       "      <td>39.0438</td>\n",
       "      <td>-0.424660</td>\n",
       "      <td>-0.905353</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17622</th>\n",
       "      <td>54.8454</td>\n",
       "      <td>54.8454</td>\n",
       "      <td>-0.254813</td>\n",
       "      <td>0.966990</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3191</th>\n",
       "      <td>-77.4874</td>\n",
       "      <td>39.0438</td>\n",
       "      <td>-0.032792</td>\n",
       "      <td>0.999462</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>-122.6760</td>\n",
       "      <td>45.5235</td>\n",
       "      <td>-0.423804</td>\n",
       "      <td>-0.905754</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3303</th>\n",
       "      <td>-121.8950</td>\n",
       "      <td>37.3394</td>\n",
       "      <td>0.675644</td>\n",
       "      <td>0.737228</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16660</th>\n",
       "      <td>54.8865</td>\n",
       "      <td>54.8865</td>\n",
       "      <td>-0.318753</td>\n",
       "      <td>0.947838</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17410</th>\n",
       "      <td>54.2458</td>\n",
       "      <td>54.2458</td>\n",
       "      <td>-0.268429</td>\n",
       "      <td>0.963299</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16454</th>\n",
       "      <td>52.6720</td>\n",
       "      <td>52.6720</td>\n",
       "      <td>-0.349049</td>\n",
       "      <td>0.937104</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17573</th>\n",
       "      <td>51.0942</td>\n",
       "      <td>51.0942</td>\n",
       "      <td>-0.258257</td>\n",
       "      <td>0.966076</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4178 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            lon      lat  sin_time  cos_time  valid\n",
       "1659   -80.0913  40.4012  0.119415 -0.992844      0\n",
       "497    -77.4874  39.0438 -0.424660 -0.905353      0\n",
       "17622   54.8454  54.8454 -0.254813  0.966990      1\n",
       "3191   -77.4874  39.0438 -0.032792  0.999462      0\n",
       "238   -122.6760  45.5235 -0.423804 -0.905754      0\n",
       "...         ...      ...       ...       ...    ...\n",
       "3303  -121.8950  37.3394  0.675644  0.737228      0\n",
       "16660   54.8865  54.8865 -0.318753  0.947838      1\n",
       "17410   54.2458  54.2458 -0.268429  0.963299      1\n",
       "16454   52.6720  52.6720 -0.349049  0.937104      1\n",
       "17573   51.0942  51.0942 -0.258257  0.966076      1\n",
       "\n",
       "[4178 rows x 5 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle \n",
    "\n",
    "with open(\"frames.bin\", \"rb\") as f:\n",
    "    df = pickle.load(f) \n",
    "\n",
    "df = df[df['lon'] != 0]\n",
    "fraud = df[df['valid'] == 0]\n",
    "nofraud = df[df['valid'] == 1]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "\n",
    "frames = pd.concat([nofraud, fraud])\n",
    "x = frames.iloc[:,0:4].to_numpy()\n",
    "y = frames.iloc[:,4:5]\n",
    "\n",
    "sX_resampled, sy_resampled = SMOTE().fit_resample(x, y)\n",
    "aX_resampled, ay_resampled = ADASYN().fit_resample(x, y)\n",
    "\n",
    "y = pd.get_dummies(sy_resampled.valid).to_numpy()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(sX_resampled, y, test_size=0.33, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SMOTE Based sampling with all fraud records neural network classifier, accuracy testing 98%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 5.9712 - accuracy: 0.5658\n",
      "Epoch 2/150\n",
      "286/286 [==============================] - 0s 955us/step - loss: 2.7955 - accuracy: 0.6156\n",
      "Epoch 3/150\n",
      "286/286 [==============================] - 0s 997us/step - loss: 1.4580 - accuracy: 0.6114\n",
      "Epoch 4/150\n",
      "286/286 [==============================] - 0s 976us/step - loss: 1.0827 - accuracy: 0.6058\n",
      "Epoch 5/150\n",
      "286/286 [==============================] - 0s 997us/step - loss: 0.9274 - accuracy: 0.5973\n",
      "Epoch 6/150\n",
      "286/286 [==============================] - 0s 990us/step - loss: 0.7792 - accuracy: 0.5966\n",
      "Epoch 7/150\n",
      "286/286 [==============================] - 0s 997us/step - loss: 0.7436 - accuracy: 0.6015\n",
      "Epoch 8/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.7542 - accuracy: 0.6170\n",
      "Epoch 9/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.7011 - accuracy: 0.6128\n",
      "Epoch 10/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.6655 - accuracy: 0.6131\n",
      "Epoch 11/150\n",
      "286/286 [==============================] - 0s 973us/step - loss: 0.7197 - accuracy: 0.6135\n",
      "Epoch 12/150\n",
      "286/286 [==============================] - 0s 976us/step - loss: 0.6380 - accuracy: 0.6131\n",
      "Epoch 13/150\n",
      "286/286 [==============================] - 0s 997us/step - loss: 0.6628 - accuracy: 0.6149\n",
      "Epoch 14/150\n",
      "286/286 [==============================] - 0s 987us/step - loss: 0.6753 - accuracy: 0.6212\n",
      "Epoch 15/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.7029 - accuracy: 0.6215\n",
      "Epoch 16/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.6050 - accuracy: 0.6380\n",
      "Epoch 17/150\n",
      "286/286 [==============================] - 0s 976us/step - loss: 0.6484 - accuracy: 0.6380\n",
      "Epoch 18/150\n",
      "286/286 [==============================] - 0s 966us/step - loss: 0.6246 - accuracy: 0.6286\n",
      "Epoch 19/150\n",
      "286/286 [==============================] - 0s 973us/step - loss: 0.6117 - accuracy: 0.6349\n",
      "Epoch 20/150\n",
      "286/286 [==============================] - 0s 973us/step - loss: 0.6190 - accuracy: 0.6433\n",
      "Epoch 21/150\n",
      "286/286 [==============================] - 0s 976us/step - loss: 0.6356 - accuracy: 0.6398\n",
      "Epoch 22/150\n",
      "286/286 [==============================] - 0s 983us/step - loss: 0.6303 - accuracy: 0.6377\n",
      "Epoch 23/150\n",
      "286/286 [==============================] - 0s 976us/step - loss: 0.6197 - accuracy: 0.6478\n",
      "Epoch 24/150\n",
      "286/286 [==============================] - 0s 983us/step - loss: 0.6421 - accuracy: 0.6436\n",
      "Epoch 25/150\n",
      "286/286 [==============================] - 0s 945us/step - loss: 0.5895 - accuracy: 0.6570\n",
      "Epoch 26/150\n",
      "286/286 [==============================] - 0s 931us/step - loss: 0.6247 - accuracy: 0.6559\n",
      "Epoch 27/150\n",
      "286/286 [==============================] - 0s 931us/step - loss: 0.5717 - accuracy: 0.6713\n",
      "Epoch 28/150\n",
      "286/286 [==============================] - 0s 924us/step - loss: 0.5741 - accuracy: 0.6668\n",
      "Epoch 29/150\n",
      "286/286 [==============================] - 0s 921us/step - loss: 0.5985 - accuracy: 0.6780\n",
      "Epoch 30/150\n",
      "286/286 [==============================] - 0s 900us/step - loss: 0.6120 - accuracy: 0.6889\n",
      "Epoch 31/150\n",
      "286/286 [==============================] - 0s 921us/step - loss: 0.5702 - accuracy: 0.6780\n",
      "Epoch 32/150\n",
      "286/286 [==============================] - 0s 917us/step - loss: 0.6436 - accuracy: 0.6892\n",
      "Epoch 33/150\n",
      "286/286 [==============================] - 0s 921us/step - loss: 0.5570 - accuracy: 0.7012\n",
      "Epoch 34/150\n",
      "286/286 [==============================] - 0s 945us/step - loss: 0.5696 - accuracy: 0.7015\n",
      "Epoch 35/150\n",
      "286/286 [==============================] - 0s 921us/step - loss: 0.5492 - accuracy: 0.7085\n",
      "Epoch 36/150\n",
      "286/286 [==============================] - 0s 921us/step - loss: 0.5452 - accuracy: 0.7113\n",
      "Epoch 37/150\n",
      "286/286 [==============================] - 0s 917us/step - loss: 0.5955 - accuracy: 0.7145\n",
      "Epoch 38/150\n",
      "286/286 [==============================] - 0s 921us/step - loss: 0.5368 - accuracy: 0.7215\n",
      "Epoch 39/150\n",
      "286/286 [==============================] - 0s 949us/step - loss: 0.5491 - accuracy: 0.7243\n",
      "Epoch 40/150\n",
      "286/286 [==============================] - 0s 938us/step - loss: 0.5811 - accuracy: 0.7162\n",
      "Epoch 41/150\n",
      "286/286 [==============================] - 0s 924us/step - loss: 0.5265 - accuracy: 0.7268\n",
      "Epoch 42/150\n",
      "286/286 [==============================] - 0s 928us/step - loss: 0.5488 - accuracy: 0.7313\n",
      "Epoch 43/150\n",
      "286/286 [==============================] - 0s 935us/step - loss: 0.5162 - accuracy: 0.7359\n",
      "Epoch 44/150\n",
      "286/286 [==============================] - 0s 962us/step - loss: 0.5331 - accuracy: 0.7334\n",
      "Epoch 45/150\n",
      "286/286 [==============================] - 0s 931us/step - loss: 0.5131 - accuracy: 0.7450\n",
      "Epoch 46/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5232 - accuracy: 0.7552\n",
      "Epoch 47/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5022 - accuracy: 0.7489\n",
      "Epoch 48/150\n",
      "286/286 [==============================] - 0s 942us/step - loss: 0.5209 - accuracy: 0.7408\n",
      "Epoch 49/150\n",
      "286/286 [==============================] - 0s 931us/step - loss: 0.5276 - accuracy: 0.7383\n",
      "Epoch 50/150\n",
      "286/286 [==============================] - 0s 931us/step - loss: 0.4924 - accuracy: 0.7566\n",
      "Epoch 51/150\n",
      "286/286 [==============================] - 0s 910us/step - loss: 0.5104 - accuracy: 0.7531\n",
      "Epoch 52/150\n",
      "286/286 [==============================] - 0s 907us/step - loss: 0.4894 - accuracy: 0.7601\n",
      "Epoch 53/150\n",
      "286/286 [==============================] - 0s 949us/step - loss: 0.5642 - accuracy: 0.7604\n",
      "Epoch 54/150\n",
      "286/286 [==============================] - 0s 928us/step - loss: 0.5001 - accuracy: 0.7608\n",
      "Epoch 55/150\n",
      "286/286 [==============================] - 0s 942us/step - loss: 0.4959 - accuracy: 0.7794\n",
      "Epoch 56/150\n",
      "286/286 [==============================] - 0s 931us/step - loss: 0.4895 - accuracy: 0.7738\n",
      "Epoch 57/150\n",
      "286/286 [==============================] - 0s 921us/step - loss: 0.4815 - accuracy: 0.7720\n",
      "Epoch 58/150\n",
      "286/286 [==============================] - 0s 917us/step - loss: 0.4570 - accuracy: 0.7913\n",
      "Epoch 59/150\n",
      "286/286 [==============================] - 0s 914us/step - loss: 0.4653 - accuracy: 0.7994\n",
      "Epoch 60/150\n",
      "286/286 [==============================] - 0s 924us/step - loss: 0.4828 - accuracy: 0.7850\n",
      "Epoch 61/150\n",
      "286/286 [==============================] - 0s 935us/step - loss: 0.4564 - accuracy: 0.7829\n",
      "Epoch 62/150\n",
      "286/286 [==============================] - 0s 931us/step - loss: 0.4585 - accuracy: 0.7941\n",
      "Epoch 63/150\n",
      "286/286 [==============================] - 0s 942us/step - loss: 0.4899 - accuracy: 0.7959\n",
      "Epoch 64/150\n",
      "286/286 [==============================] - 0s 931us/step - loss: 0.5254 - accuracy: 0.7857\n",
      "Epoch 65/150\n",
      "286/286 [==============================] - 0s 917us/step - loss: 0.4414 - accuracy: 0.8004\n",
      "Epoch 66/150\n",
      "286/286 [==============================] - 0s 928us/step - loss: 0.4695 - accuracy: 0.7983\n",
      "Epoch 67/150\n",
      "286/286 [==============================] - 0s 921us/step - loss: 0.4456 - accuracy: 0.7976\n",
      "Epoch 68/150\n",
      "286/286 [==============================] - 0s 928us/step - loss: 0.4375 - accuracy: 0.8018\n",
      "Epoch 69/150\n",
      "286/286 [==============================] - 0s 928us/step - loss: 0.4175 - accuracy: 0.8137\n",
      "Epoch 70/150\n",
      "286/286 [==============================] - 0s 969us/step - loss: 0.4565 - accuracy: 0.8120\n",
      "Epoch 71/150\n",
      "286/286 [==============================] - 0s 935us/step - loss: 0.4627 - accuracy: 0.8109\n",
      "Epoch 72/150\n",
      "286/286 [==============================] - 0s 945us/step - loss: 0.4541 - accuracy: 0.8081\n",
      "Epoch 73/150\n",
      "286/286 [==============================] - 0s 935us/step - loss: 0.4268 - accuracy: 0.8183\n",
      "Epoch 74/150\n",
      "286/286 [==============================] - 0s 921us/step - loss: 0.4189 - accuracy: 0.8141\n",
      "Epoch 75/150\n",
      "286/286 [==============================] - 0s 924us/step - loss: 0.4336 - accuracy: 0.8134\n",
      "Epoch 76/150\n",
      "286/286 [==============================] - 0s 917us/step - loss: 0.4353 - accuracy: 0.8211\n",
      "Epoch 77/150\n",
      "286/286 [==============================] - 0s 928us/step - loss: 0.4565 - accuracy: 0.8218\n",
      "Epoch 78/150\n",
      "286/286 [==============================] - 0s 983us/step - loss: 0.4231 - accuracy: 0.8176\n",
      "Epoch 79/150\n",
      "286/286 [==============================] - 0s 945us/step - loss: 0.4844 - accuracy: 0.8145\n",
      "Epoch 80/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "286/286 [==============================] - 0s 928us/step - loss: 0.4768 - accuracy: 0.8176\n",
      "Epoch 81/150\n",
      "286/286 [==============================] - 0s 907us/step - loss: 0.4259 - accuracy: 0.8197\n",
      "Epoch 82/150\n",
      "286/286 [==============================] - 0s 917us/step - loss: 0.4149 - accuracy: 0.8204\n",
      "Epoch 83/150\n",
      "286/286 [==============================] - 0s 931us/step - loss: 0.3927 - accuracy: 0.8337\n",
      "Epoch 84/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.4480 - accuracy: 0.8337\n",
      "Epoch 85/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.4454 - accuracy: 0.8225\n",
      "Epoch 86/150\n",
      "286/286 [==============================] - 0s 921us/step - loss: 0.4393 - accuracy: 0.8208\n",
      "Epoch 87/150\n",
      "286/286 [==============================] - 0s 917us/step - loss: 0.4147 - accuracy: 0.8271\n",
      "Epoch 88/150\n",
      "286/286 [==============================] - 0s 921us/step - loss: 0.4546 - accuracy: 0.8278\n",
      "Epoch 89/150\n",
      "286/286 [==============================] - 0s 931us/step - loss: 0.4121 - accuracy: 0.8246\n",
      "Epoch 90/150\n",
      "286/286 [==============================] - 0s 921us/step - loss: 0.4619 - accuracy: 0.8323\n",
      "Epoch 91/150\n",
      "286/286 [==============================] - 0s 914us/step - loss: 0.4077 - accuracy: 0.8323\n",
      "Epoch 92/150\n",
      "286/286 [==============================] - 0s 917us/step - loss: 0.4109 - accuracy: 0.8344\n",
      "Epoch 93/150\n",
      "286/286 [==============================] - 0s 921us/step - loss: 0.4231 - accuracy: 0.8295\n",
      "Epoch 94/150\n",
      "286/286 [==============================] - 0s 924us/step - loss: 0.4282 - accuracy: 0.8306\n",
      "Epoch 95/150\n",
      "286/286 [==============================] - 0s 917us/step - loss: 0.3883 - accuracy: 0.8411\n",
      "Epoch 96/150\n",
      "286/286 [==============================] - 0s 910us/step - loss: 0.3779 - accuracy: 0.8488\n",
      "Epoch 97/150\n",
      "286/286 [==============================] - 0s 935us/step - loss: 0.3997 - accuracy: 0.8401\n",
      "Epoch 98/150\n",
      "286/286 [==============================] - 0s 917us/step - loss: 0.3876 - accuracy: 0.8513\n",
      "Epoch 99/150\n",
      "286/286 [==============================] - 0s 921us/step - loss: 0.3890 - accuracy: 0.8506\n",
      "Epoch 100/150\n",
      "286/286 [==============================] - 0s 928us/step - loss: 0.4377 - accuracy: 0.8299\n",
      "Epoch 101/150\n",
      "286/286 [==============================] - 0s 928us/step - loss: 0.3997 - accuracy: 0.8411\n",
      "Epoch 102/150\n",
      "286/286 [==============================] - 0s 917us/step - loss: 0.3826 - accuracy: 0.8464\n",
      "Epoch 103/150\n",
      "286/286 [==============================] - 0s 917us/step - loss: 0.4155 - accuracy: 0.8373\n",
      "Epoch 104/150\n",
      "286/286 [==============================] - 0s 921us/step - loss: 0.4111 - accuracy: 0.8390\n",
      "Epoch 105/150\n",
      "286/286 [==============================] - 0s 921us/step - loss: 0.3767 - accuracy: 0.8432\n",
      "Epoch 106/150\n",
      "286/286 [==============================] - 0s 928us/step - loss: 0.3934 - accuracy: 0.8506\n",
      "Epoch 107/150\n",
      "286/286 [==============================] - 0s 959us/step - loss: 0.3959 - accuracy: 0.8397\n",
      "Epoch 108/150\n",
      "286/286 [==============================] - 0s 942us/step - loss: 0.4065 - accuracy: 0.8422\n",
      "Epoch 109/150\n",
      "286/286 [==============================] - 0s 942us/step - loss: 0.4007 - accuracy: 0.8446\n",
      "Epoch 110/150\n",
      "286/286 [==============================] - 0s 921us/step - loss: 0.3736 - accuracy: 0.8537\n",
      "Epoch 111/150\n",
      "286/286 [==============================] - 0s 942us/step - loss: 0.3897 - accuracy: 0.8541\n",
      "Epoch 112/150\n",
      "286/286 [==============================] - 0s 931us/step - loss: 0.3981 - accuracy: 0.8453\n",
      "Epoch 113/150\n",
      "286/286 [==============================] - 0s 931us/step - loss: 0.3949 - accuracy: 0.8446\n",
      "Epoch 114/150\n",
      "286/286 [==============================] - 0s 945us/step - loss: 0.3900 - accuracy: 0.8502\n",
      "Epoch 115/150\n",
      "286/286 [==============================] - 0s 924us/step - loss: 0.3864 - accuracy: 0.8520\n",
      "Epoch 116/150\n",
      "286/286 [==============================] - 0s 917us/step - loss: 0.3877 - accuracy: 0.8565\n",
      "Epoch 117/150\n",
      "286/286 [==============================] - 0s 921us/step - loss: 0.3995 - accuracy: 0.8408\n",
      "Epoch 118/150\n",
      "286/286 [==============================] - 0s 931us/step - loss: 0.3663 - accuracy: 0.8530\n",
      "Epoch 119/150\n",
      "286/286 [==============================] - 0s 935us/step - loss: 0.4403 - accuracy: 0.8415\n",
      "Epoch 120/150\n",
      "286/286 [==============================] - 0s 931us/step - loss: 0.4349 - accuracy: 0.8464\n",
      "Epoch 121/150\n",
      "286/286 [==============================] - 0s 931us/step - loss: 0.3726 - accuracy: 0.8530\n",
      "Epoch 122/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.3872 - accuracy: 0.8481\n",
      "Epoch 123/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.3853 - accuracy: 0.8485\n",
      "Epoch 124/150\n",
      "286/286 [==============================] - 0s 928us/step - loss: 0.3837 - accuracy: 0.8551\n",
      "Epoch 125/150\n",
      "286/286 [==============================] - 0s 924us/step - loss: 0.3950 - accuracy: 0.8499\n",
      "Epoch 126/150\n",
      "286/286 [==============================] - 0s 921us/step - loss: 0.3624 - accuracy: 0.8639\n",
      "Epoch 127/150\n",
      "286/286 [==============================] - 0s 942us/step - loss: 0.3676 - accuracy: 0.8551\n",
      "Epoch 128/150\n",
      "286/286 [==============================] - 0s 921us/step - loss: 0.3639 - accuracy: 0.8593\n",
      "Epoch 129/150\n",
      "286/286 [==============================] - 0s 928us/step - loss: 0.3619 - accuracy: 0.8590\n",
      "Epoch 130/150\n",
      "286/286 [==============================] - 0s 931us/step - loss: 0.4018 - accuracy: 0.8513\n",
      "Epoch 131/150\n",
      "286/286 [==============================] - 0s 959us/step - loss: 0.3856 - accuracy: 0.8530\n",
      "Epoch 132/150\n",
      "286/286 [==============================] - 0s 921us/step - loss: 0.3752 - accuracy: 0.8579\n",
      "Epoch 133/150\n",
      "286/286 [==============================] - 0s 928us/step - loss: 0.3872 - accuracy: 0.8467\n",
      "Epoch 134/150\n",
      "286/286 [==============================] - 0s 945us/step - loss: 0.4402 - accuracy: 0.8562\n",
      "Epoch 135/150\n",
      "286/286 [==============================] - 0s 945us/step - loss: 0.3618 - accuracy: 0.8583\n",
      "Epoch 136/150\n",
      "286/286 [==============================] - 0s 962us/step - loss: 0.3650 - accuracy: 0.8674\n",
      "Epoch 137/150\n",
      "286/286 [==============================] - 0s 928us/step - loss: 0.3795 - accuracy: 0.8460\n",
      "Epoch 138/150\n",
      "286/286 [==============================] - 0s 924us/step - loss: 0.4372 - accuracy: 0.8358\n",
      "Epoch 139/150\n",
      "286/286 [==============================] - 0s 931us/step - loss: 0.3703 - accuracy: 0.8537\n",
      "Epoch 140/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.3612 - accuracy: 0.8590\n",
      "Epoch 141/150\n",
      "286/286 [==============================] - 0s 931us/step - loss: 0.3930 - accuracy: 0.8495\n",
      "Epoch 142/150\n",
      "286/286 [==============================] - 0s 917us/step - loss: 0.3578 - accuracy: 0.8565\n",
      "Epoch 143/150\n",
      "286/286 [==============================] - 0s 924us/step - loss: 0.3775 - accuracy: 0.8513\n",
      "Epoch 144/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.3598 - accuracy: 0.8678\n",
      "Epoch 145/150\n",
      "286/286 [==============================] - 0s 938us/step - loss: 0.3544 - accuracy: 0.8576\n",
      "Epoch 146/150\n",
      "286/286 [==============================] - 0s 917us/step - loss: 0.3916 - accuracy: 0.8537\n",
      "Epoch 147/150\n",
      "286/286 [==============================] - 0s 928us/step - loss: 0.3755 - accuracy: 0.8534\n",
      "Epoch 148/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.3556 - accuracy: 0.8608\n",
      "Epoch 149/150\n",
      "286/286 [==============================] - 0s 924us/step - loss: 0.3551 - accuracy: 0.8586\n",
      "Epoch 150/150\n",
      "286/286 [==============================] - 0s 949us/step - loss: 0.4025 - accuracy: 0.8429\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1493 - accuracy: 0.9879\n",
      "Accuracy: 98.79\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=4, activation='relu'))\n",
    "model.add(Dropout(0.7))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dropout(0.7))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dropout(0.7))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dropout(0.7))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=150, batch_size=10)\n",
    "\n",
    "_, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SMOTE Based Neural Network classifier with 500 records, accuracy testing : 99%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.3734 - accuracy: 0.8485\n",
      "Epoch 2/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.3988 - accuracy: 0.8520\n",
      "Epoch 3/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.3806 - accuracy: 0.8502\n",
      "Epoch 4/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.3848 - accuracy: 0.8530\n",
      "Epoch 5/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.3787 - accuracy: 0.8495\n",
      "Epoch 6/150\n",
      "286/286 [==============================] - 0s 969us/step - loss: 0.4147 - accuracy: 0.8369\n",
      "Epoch 7/150\n",
      "286/286 [==============================] - 0s 976us/step - loss: 0.4071 - accuracy: 0.8460\n",
      "Epoch 8/150\n",
      "286/286 [==============================] - 0s 990us/step - loss: 0.4571 - accuracy: 0.8313\n",
      "Epoch 9/150\n",
      "286/286 [==============================] - 0s 973us/step - loss: 0.4056 - accuracy: 0.8299\n",
      "Epoch 10/150\n",
      "286/286 [==============================] - 0s 973us/step - loss: 0.3948 - accuracy: 0.8443\n",
      "Epoch 11/150\n",
      "286/286 [==============================] - 0s 987us/step - loss: 0.4078 - accuracy: 0.8344\n",
      "Epoch 12/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.3772 - accuracy: 0.8443\n",
      "Epoch 13/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.3762 - accuracy: 0.8457\n",
      "Epoch 14/150\n",
      "286/286 [==============================] - 0s 966us/step - loss: 0.4181 - accuracy: 0.8271\n",
      "Epoch 15/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.4012 - accuracy: 0.8432\n",
      "Epoch 16/150\n",
      "286/286 [==============================] - 0s 966us/step - loss: 0.4242 - accuracy: 0.8411\n",
      "Epoch 17/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.4214 - accuracy: 0.8358\n",
      "Epoch 18/150\n",
      "286/286 [==============================] - 0s 942us/step - loss: 0.4229 - accuracy: 0.8337\n",
      "Epoch 19/150\n",
      "286/286 [==============================] - 0s 959us/step - loss: 0.4350 - accuracy: 0.8155\n",
      "Epoch 20/150\n",
      "286/286 [==============================] - 0s 976us/step - loss: 0.4564 - accuracy: 0.8043\n",
      "Epoch 21/150\n",
      "286/286 [==============================] - 0s 994us/step - loss: 0.4299 - accuracy: 0.8183\n",
      "Epoch 22/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.4480 - accuracy: 0.8243\n",
      "Epoch 23/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.4333 - accuracy: 0.8187\n",
      "Epoch 24/150\n",
      "286/286 [==============================] - 0s 945us/step - loss: 0.4154 - accuracy: 0.8194\n",
      "Epoch 25/150\n",
      "286/286 [==============================] - 0s 935us/step - loss: 0.4036 - accuracy: 0.8250\n",
      "Epoch 26/150\n",
      "286/286 [==============================] - 0s 955us/step - loss: 0.4199 - accuracy: 0.8278\n",
      "Epoch 27/150\n",
      "286/286 [==============================] - 0s 945us/step - loss: 0.4373 - accuracy: 0.8183\n",
      "Epoch 28/150\n",
      "286/286 [==============================] - 0s 955us/step - loss: 0.4099 - accuracy: 0.8243\n",
      "Epoch 29/150\n",
      "286/286 [==============================] - 0s 955us/step - loss: 0.4434 - accuracy: 0.8271\n",
      "Epoch 30/150\n",
      "286/286 [==============================] - 0s 938us/step - loss: 0.4243 - accuracy: 0.8155\n",
      "Epoch 31/150\n",
      "286/286 [==============================] - 0s 949us/step - loss: 0.4345 - accuracy: 0.8102\n",
      "Epoch 32/150\n",
      "286/286 [==============================] - 0s 955us/step - loss: 0.4718 - accuracy: 0.8183\n",
      "Epoch 33/150\n",
      "286/286 [==============================] - 0s 955us/step - loss: 0.4029 - accuracy: 0.8267\n",
      "Epoch 34/150\n",
      "286/286 [==============================] - 0s 945us/step - loss: 0.4397 - accuracy: 0.8201\n",
      "Epoch 35/150\n",
      "286/286 [==============================] - 0s 938us/step - loss: 0.4387 - accuracy: 0.8176\n",
      "Epoch 36/150\n",
      "286/286 [==============================] - 0s 942us/step - loss: 0.4309 - accuracy: 0.8176\n",
      "Epoch 37/150\n",
      "286/286 [==============================] - 0s 928us/step - loss: 0.4670 - accuracy: 0.8152\n",
      "Epoch 38/150\n",
      "286/286 [==============================] - 0s 924us/step - loss: 0.3969 - accuracy: 0.8250\n",
      "Epoch 39/150\n",
      "286/286 [==============================] - 0s 935us/step - loss: 0.3972 - accuracy: 0.8365\n",
      "Epoch 40/150\n",
      "286/286 [==============================] - 0s 949us/step - loss: 0.4189 - accuracy: 0.8225\n",
      "Epoch 41/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.4969 - accuracy: 0.8050\n",
      "Epoch 42/150\n",
      "286/286 [==============================] - 0s 994us/step - loss: 0.4293 - accuracy: 0.8190\n",
      "Epoch 43/150\n",
      "286/286 [==============================] - 0s 990us/step - loss: 0.4549 - accuracy: 0.8113\n",
      "Epoch 44/150\n",
      "286/286 [==============================] - 0s 987us/step - loss: 0.4065 - accuracy: 0.8257\n",
      "Epoch 45/150\n",
      "286/286 [==============================] - 0s 990us/step - loss: 0.4357 - accuracy: 0.8152\n",
      "Epoch 46/150\n",
      "286/286 [==============================] - 0s 980us/step - loss: 0.4195 - accuracy: 0.8222\n",
      "Epoch 47/150\n",
      "286/286 [==============================] - 0s 966us/step - loss: 0.4506 - accuracy: 0.8187\n",
      "Epoch 48/150\n",
      "286/286 [==============================] - 0s 976us/step - loss: 0.4542 - accuracy: 0.8190\n",
      "Epoch 49/150\n",
      "286/286 [==============================] - 0s 973us/step - loss: 0.4714 - accuracy: 0.8039\n",
      "Epoch 50/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.4179 - accuracy: 0.8260\n",
      "Epoch 51/150\n",
      "286/286 [==============================] - 0s 973us/step - loss: 0.4483 - accuracy: 0.8137\n",
      "Epoch 52/150\n",
      "286/286 [==============================] - 0s 955us/step - loss: 0.4557 - accuracy: 0.8088\n",
      "Epoch 53/150\n",
      "286/286 [==============================] - 0s 983us/step - loss: 0.4252 - accuracy: 0.8137\n",
      "Epoch 54/150\n",
      "286/286 [==============================] - 0s 952us/step - loss: 0.4468 - accuracy: 0.8148\n",
      "Epoch 55/150\n",
      "286/286 [==============================] - 0s 966us/step - loss: 0.4444 - accuracy: 0.8180\n",
      "Epoch 56/150\n",
      "286/286 [==============================] - 0s 935us/step - loss: 0.4303 - accuracy: 0.8120\n",
      "Epoch 57/150\n",
      "286/286 [==============================] - 0s 973us/step - loss: 0.4866 - accuracy: 0.8057\n",
      "Epoch 58/150\n",
      "286/286 [==============================] - 0s 938us/step - loss: 0.4205 - accuracy: 0.8264\n",
      "Epoch 59/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.4096 - accuracy: 0.8236\n",
      "Epoch 60/150\n",
      "286/286 [==============================] - 0s 969us/step - loss: 0.4119 - accuracy: 0.8243\n",
      "Epoch 61/150\n",
      "286/286 [==============================] - 0s 987us/step - loss: 0.4132 - accuracy: 0.8292\n",
      "Epoch 62/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.3950 - accuracy: 0.8295\n",
      "Epoch 63/150\n",
      "286/286 [==============================] - 0s 990us/step - loss: 0.4322 - accuracy: 0.8330\n",
      "Epoch 64/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.4782 - accuracy: 0.8218\n",
      "Epoch 65/150\n",
      "286/286 [==============================] - 0s 945us/step - loss: 0.4177 - accuracy: 0.8148\n",
      "Epoch 66/150\n",
      "286/286 [==============================] - 0s 942us/step - loss: 0.4271 - accuracy: 0.8299\n",
      "Epoch 67/150\n",
      "286/286 [==============================] - 0s 949us/step - loss: 0.4101 - accuracy: 0.8194\n",
      "Epoch 68/150\n",
      "286/286 [==============================] - 0s 942us/step - loss: 0.4296 - accuracy: 0.8183\n",
      "Epoch 69/150\n",
      "286/286 [==============================] - 0s 955us/step - loss: 0.3985 - accuracy: 0.8250\n",
      "Epoch 70/150\n",
      "286/286 [==============================] - 0s 931us/step - loss: 0.4171 - accuracy: 0.8211\n",
      "Epoch 71/150\n",
      "286/286 [==============================] - 0s 959us/step - loss: 0.4307 - accuracy: 0.8134\n",
      "Epoch 72/150\n",
      "286/286 [==============================] - 0s 949us/step - loss: 0.4044 - accuracy: 0.8169\n",
      "Epoch 73/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.4566 - accuracy: 0.8152\n",
      "Epoch 74/150\n",
      "286/286 [==============================] - 0s 976us/step - loss: 0.4309 - accuracy: 0.8222\n",
      "Epoch 75/150\n",
      "286/286 [==============================] - 0s 952us/step - loss: 0.4205 - accuracy: 0.8225\n",
      "Epoch 76/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.4489 - accuracy: 0.8092\n",
      "Epoch 77/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.4011 - accuracy: 0.8306\n",
      "Epoch 78/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.4231 - accuracy: 0.8197\n",
      "Epoch 79/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5041 - accuracy: 0.7636\n",
      "Epoch 80/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5033 - accuracy: 0.7531\n",
      "Epoch 81/150\n",
      "286/286 [==============================] - 0s 931us/step - loss: 0.4765 - accuracy: 0.7776\n",
      "Epoch 82/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.4771 - accuracy: 0.7804\n",
      "Epoch 83/150\n",
      "286/286 [==============================] - 0s 952us/step - loss: 0.4676 - accuracy: 0.7927\n",
      "Epoch 84/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.4466 - accuracy: 0.7945\n",
      "Epoch 85/150\n",
      "286/286 [==============================] - 0s 938us/step - loss: 0.4689 - accuracy: 0.7888\n",
      "Epoch 86/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.4443 - accuracy: 0.7895\n",
      "Epoch 87/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.4730 - accuracy: 0.7980\n",
      "Epoch 88/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.4632 - accuracy: 0.7906\n",
      "Epoch 89/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.4580 - accuracy: 0.7959\n",
      "Epoch 90/150\n",
      "286/286 [==============================] - 0s 980us/step - loss: 0.4506 - accuracy: 0.7962\n",
      "Epoch 91/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.4413 - accuracy: 0.7969\n",
      "Epoch 92/150\n",
      "286/286 [==============================] - 0s 921us/step - loss: 0.4721 - accuracy: 0.7818\n",
      "Epoch 93/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.4887 - accuracy: 0.7948\n",
      "Epoch 94/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.4615 - accuracy: 0.7878\n",
      "Epoch 95/150\n",
      "286/286 [==============================] - 0s 931us/step - loss: 0.4438 - accuracy: 0.7941\n",
      "Epoch 96/150\n",
      "286/286 [==============================] - 0s 997us/step - loss: 0.4405 - accuracy: 0.8113\n",
      "Epoch 97/150\n",
      "286/286 [==============================] - 0s 994us/step - loss: 0.4420 - accuracy: 0.7959\n",
      "Epoch 98/150\n",
      "286/286 [==============================] - 0s 942us/step - loss: 0.4506 - accuracy: 0.7966\n",
      "Epoch 99/150\n",
      "286/286 [==============================] - 0s 935us/step - loss: 0.4440 - accuracy: 0.7983\n",
      "Epoch 100/150\n",
      "286/286 [==============================] - 0s 980us/step - loss: 0.4681 - accuracy: 0.7895\n",
      "Epoch 101/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.4808 - accuracy: 0.7885\n",
      "Epoch 102/150\n",
      "286/286 [==============================] - 0s 955us/step - loss: 0.4629 - accuracy: 0.7776\n",
      "Epoch 103/150\n",
      "286/286 [==============================] - 0s 962us/step - loss: 0.4402 - accuracy: 0.7931\n",
      "Epoch 104/150\n",
      "286/286 [==============================] - 0s 969us/step - loss: 0.4475 - accuracy: 0.8022\n",
      "Epoch 105/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.4636 - accuracy: 0.7853\n",
      "Epoch 106/150\n",
      "286/286 [==============================] - 0s 935us/step - loss: 0.4405 - accuracy: 0.7997\n",
      "Epoch 107/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.4532 - accuracy: 0.7871\n",
      "Epoch 108/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.4739 - accuracy: 0.7804\n",
      "Epoch 109/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5419 - accuracy: 0.7552\n",
      "Epoch 110/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.4738 - accuracy: 0.7629\n",
      "Epoch 111/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.4876 - accuracy: 0.7650\n",
      "Epoch 112/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5014 - accuracy: 0.7559\n",
      "Epoch 113/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.4797 - accuracy: 0.7604\n",
      "Epoch 114/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.4967 - accuracy: 0.7475\n",
      "Epoch 115/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5107 - accuracy: 0.7587\n",
      "Epoch 116/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.4945 - accuracy: 0.7580\n",
      "Epoch 117/150\n",
      "286/286 [==============================] - 0s 987us/step - loss: 0.4773 - accuracy: 0.7636\n",
      "Epoch 118/150\n",
      "286/286 [==============================] - 0s 969us/step - loss: 0.4702 - accuracy: 0.7675\n",
      "Epoch 119/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.4802 - accuracy: 0.7555\n",
      "Epoch 120/150\n",
      "286/286 [==============================] - 0s 942us/step - loss: 0.5380 - accuracy: 0.7475\n",
      "Epoch 121/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.4868 - accuracy: 0.7527\n",
      "Epoch 122/150\n",
      "286/286 [==============================] - 0s 949us/step - loss: 0.4915 - accuracy: 0.7639\n",
      "Epoch 123/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.4930 - accuracy: 0.7531\n",
      "Epoch 124/150\n",
      "286/286 [==============================] - 0s 935us/step - loss: 0.4908 - accuracy: 0.7520\n",
      "Epoch 125/150\n",
      "286/286 [==============================] - 0s 955us/step - loss: 0.4816 - accuracy: 0.7629\n",
      "Epoch 126/150\n",
      "286/286 [==============================] - 0s 931us/step - loss: 0.5005 - accuracy: 0.7615\n",
      "Epoch 127/150\n",
      "286/286 [==============================] - 0s 935us/step - loss: 0.5219 - accuracy: 0.7594\n",
      "Epoch 128/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.4853 - accuracy: 0.7573\n",
      "Epoch 129/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.4911 - accuracy: 0.7538\n",
      "Epoch 130/150\n",
      "286/286 [==============================] - 0s 938us/step - loss: 0.4784 - accuracy: 0.7608\n",
      "Epoch 131/150\n",
      "286/286 [==============================] - 0s 931us/step - loss: 0.4723 - accuracy: 0.7706\n",
      "Epoch 132/150\n",
      "286/286 [==============================] - 0s 924us/step - loss: 0.5178 - accuracy: 0.7499\n",
      "Epoch 133/150\n",
      "286/286 [==============================] - 0s 931us/step - loss: 0.4930 - accuracy: 0.7583\n",
      "Epoch 134/150\n",
      "286/286 [==============================] - 0s 959us/step - loss: 0.4714 - accuracy: 0.7622\n",
      "Epoch 135/150\n",
      "286/286 [==============================] - 0s 942us/step - loss: 0.5008 - accuracy: 0.7559\n",
      "Epoch 136/150\n",
      "286/286 [==============================] - 0s 952us/step - loss: 0.5093 - accuracy: 0.7576\n",
      "Epoch 137/150\n",
      "286/286 [==============================] - 0s 942us/step - loss: 0.4766 - accuracy: 0.7569\n",
      "Epoch 138/150\n",
      "286/286 [==============================] - 0s 949us/step - loss: 0.5540 - accuracy: 0.7082\n",
      "Epoch 139/150\n",
      "286/286 [==============================] - 0s 938us/step - loss: 0.5493 - accuracy: 0.7033\n",
      "Epoch 140/150\n",
      "286/286 [==============================] - 0s 938us/step - loss: 0.5649 - accuracy: 0.7064\n",
      "Epoch 141/150\n",
      "286/286 [==============================] - 0s 945us/step - loss: 0.5510 - accuracy: 0.6931\n",
      "Epoch 142/150\n",
      "286/286 [==============================] - 0s 938us/step - loss: 0.5293 - accuracy: 0.7141\n",
      "Epoch 143/150\n",
      "286/286 [==============================] - 0s 966us/step - loss: 0.5670 - accuracy: 0.6885\n",
      "Epoch 144/150\n",
      "286/286 [==============================] - 0s 935us/step - loss: 0.5336 - accuracy: 0.7068\n",
      "Epoch 145/150\n",
      "286/286 [==============================] - 0s 973us/step - loss: 0.6300 - accuracy: 0.6271\n",
      "Epoch 146/150\n",
      "286/286 [==============================] - 0s 959us/step - loss: 0.6035 - accuracy: 0.6271\n",
      "Epoch 147/150\n",
      "286/286 [==============================] - 0s 945us/step - loss: 0.6156 - accuracy: 0.6233\n",
      "Epoch 148/150\n",
      "286/286 [==============================] - 0s 949us/step - loss: 0.6239 - accuracy: 0.6278\n",
      "Epoch 149/150\n",
      "286/286 [==============================] - 0s 952us/step - loss: 0.6304 - accuracy: 0.6128\n",
      "Epoch 150/150\n",
      "286/286 [==============================] - 0s 959us/step - loss: 0.5985 - accuracy: 0.6370\n",
      "44/44 [==============================] - 0s 816us/step - loss: 0.3016 - accuracy: 0.9900\n",
      "Accuracy: 99.00\n"
     ]
    }
   ],
   "source": [
    "fraud = frames[frames['valid']==0][:500]\n",
    "frames = pd.concat([nofraud, fraud])\n",
    "x = frames.iloc[:,0:4].to_numpy()\n",
    "y = frames.iloc[:,4:5]\n",
    "\n",
    "sX_resampled, sy_resampled = SMOTE().fit_resample(x, y)\n",
    "aX_resampled, ay_resampled = ADASYN().fit_resample(x, y)\n",
    "\n",
    "y = pd.get_dummies(sy_resampled.valid).to_numpy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(sX_resampled, y, test_size=0.33, random_state=42)\n",
    "\n",
    "model.fit(X_train, y_train, epochs=150, batch_size=10)\n",
    "\n",
    "_, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SMOTE based neural network with fraud records of 200, accuracy 48%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "286/286 [==============================] - 0s 983us/step - loss: 0.6134 - accuracy: 0.6236\n",
      "Epoch 2/150\n",
      "286/286 [==============================] - 0s 983us/step - loss: 0.6086 - accuracy: 0.6229\n",
      "Epoch 3/150\n",
      "286/286 [==============================] - 0s 990us/step - loss: 0.6006 - accuracy: 0.6286\n",
      "Epoch 4/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.6031 - accuracy: 0.6264\n",
      "Epoch 5/150\n",
      "286/286 [==============================] - 0s 969us/step - loss: 0.6136 - accuracy: 0.6201\n",
      "Epoch 6/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.6056 - accuracy: 0.6233\n",
      "Epoch 7/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.6053 - accuracy: 0.6264\n",
      "Epoch 8/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.6154 - accuracy: 0.6201\n",
      "Epoch 9/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.6125 - accuracy: 0.6163\n",
      "Epoch 10/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.6056 - accuracy: 0.6243\n",
      "Epoch 11/150\n",
      "286/286 [==============================] - 0s 997us/step - loss: 0.6061 - accuracy: 0.6254\n",
      "Epoch 12/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.6319 - accuracy: 0.6163\n",
      "Epoch 13/150\n",
      "286/286 [==============================] - 0s 938us/step - loss: 0.6115 - accuracy: 0.6159\n",
      "Epoch 14/150\n",
      "286/286 [==============================] - 0s 959us/step - loss: 0.6099 - accuracy: 0.6282\n",
      "Epoch 15/150\n",
      "286/286 [==============================] - 0s 955us/step - loss: 0.6106 - accuracy: 0.6215\n",
      "Epoch 16/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.6191 - accuracy: 0.6096\n",
      "Epoch 17/150\n",
      "286/286 [==============================] - 0s 938us/step - loss: 0.6226 - accuracy: 0.6075\n",
      "Epoch 18/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.6123 - accuracy: 0.6222\n",
      "Epoch 19/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.6216 - accuracy: 0.6187\n",
      "Epoch 20/150\n",
      "286/286 [==============================] - 0s 987us/step - loss: 0.6016 - accuracy: 0.6310\n",
      "Epoch 21/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.6093 - accuracy: 0.6212\n",
      "Epoch 22/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.6272 - accuracy: 0.6250\n",
      "Epoch 23/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.6063 - accuracy: 0.6201\n",
      "Epoch 24/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.6118 - accuracy: 0.6138\n",
      "Epoch 25/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.6032 - accuracy: 0.6247\n",
      "Epoch 26/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.6159 - accuracy: 0.6145\n",
      "Epoch 27/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.6096 - accuracy: 0.6233\n",
      "Epoch 28/150\n",
      "286/286 [==============================] - 0s 952us/step - loss: 0.6406 - accuracy: 0.6117\n",
      "Epoch 29/150\n",
      "286/286 [==============================] - 0s 973us/step - loss: 0.6941 - accuracy: 0.5198\n",
      "Epoch 30/150\n",
      "286/286 [==============================] - 0s 994us/step - loss: 0.6908 - accuracy: 0.5377\n",
      "Epoch 31/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.6927 - accuracy: 0.5268\n",
      "Epoch 32/150\n",
      "286/286 [==============================] - 0s 983us/step - loss: 0.6909 - accuracy: 0.5353\n",
      "Epoch 33/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.5293\n",
      "Epoch 34/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.6915 - accuracy: 0.5374\n",
      "Epoch 35/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.6906 - accuracy: 0.5328\n",
      "Epoch 36/150\n",
      "286/286 [==============================] - 0s 994us/step - loss: 0.6910 - accuracy: 0.5345\n",
      "Epoch 37/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.6908 - accuracy: 0.5349\n",
      "Epoch 38/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.6915 - accuracy: 0.5247\n",
      "Epoch 39/150\n",
      "286/286 [==============================] - 0s 997us/step - loss: 0.6927 - accuracy: 0.5244\n",
      "Epoch 40/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.6913 - accuracy: 0.5247\n",
      "Epoch 41/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.6906 - accuracy: 0.5416\n",
      "Epoch 42/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.5296\n",
      "Epoch 43/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.6909 - accuracy: 0.5367\n",
      "Epoch 44/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5167\n",
      "Epoch 45/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.5205\n",
      "Epoch 46/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.6901 - accuracy: 0.5447\n",
      "Epoch 47/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.6900 - accuracy: 0.5381\n",
      "Epoch 48/150\n",
      "286/286 [==============================] - 0s 962us/step - loss: 0.6905 - accuracy: 0.5479\n",
      "Epoch 49/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.6890 - accuracy: 0.5454\n",
      "Epoch 50/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.6895 - accuracy: 0.5416\n",
      "Epoch 51/150\n",
      "286/286 [==============================] - 0s 955us/step - loss: 0.6905 - accuracy: 0.5409\n",
      "Epoch 52/150\n",
      "286/286 [==============================] - 0s 969us/step - loss: 0.6905 - accuracy: 0.5345\n",
      "Epoch 53/150\n",
      "286/286 [==============================] - 0s 969us/step - loss: 0.6905 - accuracy: 0.5433\n",
      "Epoch 54/150\n",
      "286/286 [==============================] - 0s 955us/step - loss: 0.6915 - accuracy: 0.5349\n",
      "Epoch 55/150\n",
      "286/286 [==============================] - 0s 945us/step - loss: 0.6903 - accuracy: 0.5384\n",
      "Epoch 56/150\n",
      "286/286 [==============================] - 0s 969us/step - loss: 0.6921 - accuracy: 0.5254\n",
      "Epoch 57/150\n",
      "286/286 [==============================] - 0s 938us/step - loss: 0.6916 - accuracy: 0.5335\n",
      "Epoch 58/150\n",
      "286/286 [==============================] - 0s 945us/step - loss: 0.6911 - accuracy: 0.5360\n",
      "Epoch 59/150\n",
      "286/286 [==============================] - 0s 931us/step - loss: 0.6904 - accuracy: 0.5412\n",
      "Epoch 60/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.6909 - accuracy: 0.5349\n",
      "Epoch 61/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5191\n",
      "Epoch 62/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.6904 - accuracy: 0.5433\n",
      "Epoch 63/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.6895 - accuracy: 0.5468\n",
      "Epoch 64/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.6917 - accuracy: 0.5345\n",
      "Epoch 65/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.6913 - accuracy: 0.5367\n",
      "Epoch 66/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.6908 - accuracy: 0.5433\n",
      "Epoch 67/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.6908 - accuracy: 0.5370\n",
      "Epoch 68/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.6909 - accuracy: 0.5310\n",
      "Epoch 69/150\n",
      "286/286 [==============================] - 0s 955us/step - loss: 0.6909 - accuracy: 0.5353\n",
      "Epoch 70/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.6904 - accuracy: 0.5349\n",
      "Epoch 71/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5275\n",
      "Epoch 72/150\n",
      "286/286 [==============================] - 0s 949us/step - loss: 0.6911 - accuracy: 0.5402\n",
      "Epoch 73/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.6906 - accuracy: 0.5391\n",
      "Epoch 74/150\n",
      "286/286 [==============================] - 0s 952us/step - loss: 0.6894 - accuracy: 0.5419\n",
      "Epoch 75/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.6881 - accuracy: 0.5437\n",
      "Epoch 76/150\n",
      "286/286 [==============================] - 0s 987us/step - loss: 0.6938 - accuracy: 0.5177\n",
      "Epoch 77/150\n",
      "286/286 [==============================] - 0s 955us/step - loss: 0.6895 - accuracy: 0.5503\n",
      "Epoch 78/150\n",
      "286/286 [==============================] - 0s 928us/step - loss: 0.6922 - accuracy: 0.5331\n",
      "Epoch 79/150\n",
      "286/286 [==============================] - 0s 942us/step - loss: 0.6903 - accuracy: 0.5447\n",
      "Epoch 80/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "286/286 [==============================] - 0s 949us/step - loss: 0.6916 - accuracy: 0.5395\n",
      "Epoch 81/150\n",
      "286/286 [==============================] - 0s 959us/step - loss: 0.6900 - accuracy: 0.5409\n",
      "Epoch 82/150\n",
      "286/286 [==============================] - 0s 938us/step - loss: 0.6904 - accuracy: 0.5335\n",
      "Epoch 83/150\n",
      "286/286 [==============================] - 0s 924us/step - loss: 0.6901 - accuracy: 0.5395\n",
      "Epoch 84/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.6903 - accuracy: 0.5356\n",
      "Epoch 85/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.6919 - accuracy: 0.5265\n",
      "Epoch 86/150\n",
      "286/286 [==============================] - 0s 928us/step - loss: 0.6897 - accuracy: 0.5388\n",
      "Epoch 87/150\n",
      "286/286 [==============================] - 0s 955us/step - loss: 0.6890 - accuracy: 0.5531\n",
      "Epoch 88/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.5254\n",
      "Epoch 89/150\n",
      "286/286 [==============================] - 0s 942us/step - loss: 0.6881 - accuracy: 0.5430\n",
      "Epoch 90/150\n",
      "286/286 [==============================] - 0s 935us/step - loss: 0.6921 - accuracy: 0.5328\n",
      "Epoch 91/150\n",
      "286/286 [==============================] - 0s 983us/step - loss: 0.6908 - accuracy: 0.5391\n",
      "Epoch 92/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.6906 - accuracy: 0.5317\n",
      "Epoch 93/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5303\n",
      "Epoch 94/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.5279\n",
      "Epoch 95/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.6913 - accuracy: 0.5307\n",
      "Epoch 96/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.6884 - accuracy: 0.5468\n",
      "Epoch 97/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.6914 - accuracy: 0.5300\n",
      "Epoch 98/150\n",
      "286/286 [==============================] - 0s 945us/step - loss: 0.6916 - accuracy: 0.53600s - loss: 0.6890 - accura\n",
      "Epoch 99/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5209\n",
      "Epoch 100/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.5296\n",
      "Epoch 101/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.6876 - accuracy: 0.5482: 0s - loss: 0.6895 - accura\n",
      "Epoch 102/150\n",
      "286/286 [==============================] - 0s 949us/step - loss: 0.6917 - accuracy: 0.5353\n",
      "Epoch 103/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.6896 - accuracy: 0.5451\n",
      "Epoch 104/150\n",
      "286/286 [==============================] - 0s 952us/step - loss: 0.6904 - accuracy: 0.5314\n",
      "Epoch 105/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5370\n",
      "Epoch 106/150\n",
      "286/286 [==============================] - 0s 938us/step - loss: 0.6903 - accuracy: 0.5310\n",
      "Epoch 107/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.6912 - accuracy: 0.5384\n",
      "Epoch 108/150\n",
      "286/286 [==============================] - 0s 935us/step - loss: 0.6925 - accuracy: 0.5223\n",
      "Epoch 109/150\n",
      "286/286 [==============================] - 0s 931us/step - loss: 0.6917 - accuracy: 0.5282\n",
      "Epoch 110/150\n",
      "286/286 [==============================] - 0s 931us/step - loss: 0.6901 - accuracy: 0.5388\n",
      "Epoch 111/150\n",
      "286/286 [==============================] - 0s 928us/step - loss: 0.6885 - accuracy: 0.5486\n",
      "Epoch 112/150\n",
      "286/286 [==============================] - 0s 942us/step - loss: 0.6887 - accuracy: 0.5458\n",
      "Epoch 113/150\n",
      "286/286 [==============================] - 0s 938us/step - loss: 0.6896 - accuracy: 0.5528\n",
      "Epoch 114/150\n",
      "286/286 [==============================] - 0s 931us/step - loss: 0.6917 - accuracy: 0.5258\n",
      "Epoch 115/150\n",
      "286/286 [==============================] - 0s 942us/step - loss: 0.6916 - accuracy: 0.5251\n",
      "Epoch 116/150\n",
      "286/286 [==============================] - 0s 949us/step - loss: 0.6900 - accuracy: 0.5412\n",
      "Epoch 117/150\n",
      "286/286 [==============================] - 0s 969us/step - loss: 0.6917 - accuracy: 0.5388\n",
      "Epoch 118/150\n",
      "286/286 [==============================] - 0s 942us/step - loss: 0.6901 - accuracy: 0.5430\n",
      "Epoch 119/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.5289\n",
      "Epoch 120/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.6899 - accuracy: 0.5416\n",
      "Epoch 121/150\n",
      "286/286 [==============================] - 0s 949us/step - loss: 0.6935 - accuracy: 0.5205\n",
      "Epoch 122/150\n",
      "286/286 [==============================] - 0s 952us/step - loss: 0.6903 - accuracy: 0.5419\n",
      "Epoch 123/150\n",
      "286/286 [==============================] - 0s 955us/step - loss: 0.6907 - accuracy: 0.5377\n",
      "Epoch 124/150\n",
      "286/286 [==============================] - 0s 949us/step - loss: 0.6885 - accuracy: 0.5503\n",
      "Epoch 125/150\n",
      "286/286 [==============================] - 0s 949us/step - loss: 0.6904 - accuracy: 0.5377\n",
      "Epoch 126/150\n",
      "286/286 [==============================] - 0s 935us/step - loss: 0.6887 - accuracy: 0.5409\n",
      "Epoch 127/150\n",
      "286/286 [==============================] - 0s 931us/step - loss: 0.6911 - accuracy: 0.5282\n",
      "Epoch 128/150\n",
      "286/286 [==============================] - 0s 959us/step - loss: 0.6925 - accuracy: 0.5244\n",
      "Epoch 129/150\n",
      "286/286 [==============================] - 0s 955us/step - loss: 0.6914 - accuracy: 0.5335\n",
      "Epoch 130/150\n",
      "286/286 [==============================] - 0s 952us/step - loss: 0.6900 - accuracy: 0.5405\n",
      "Epoch 131/150\n",
      "286/286 [==============================] - 0s 962us/step - loss: 0.6924 - accuracy: 0.5279\n",
      "Epoch 132/150\n",
      "286/286 [==============================] - 0s 938us/step - loss: 0.6930 - accuracy: 0.5149\n",
      "Epoch 133/150\n",
      "286/286 [==============================] - 0s 973us/step - loss: 0.6915 - accuracy: 0.5349\n",
      "Epoch 134/150\n",
      "286/286 [==============================] - 0s 983us/step - loss: 0.6915 - accuracy: 0.5303\n",
      "Epoch 135/150\n",
      "286/286 [==============================] - 0s 962us/step - loss: 0.6909 - accuracy: 0.5451\n",
      "Epoch 136/150\n",
      "286/286 [==============================] - 0s 962us/step - loss: 0.6927 - accuracy: 0.5244\n",
      "Epoch 137/150\n",
      "286/286 [==============================] - 0s 949us/step - loss: 0.6906 - accuracy: 0.5356\n",
      "Epoch 138/150\n",
      "286/286 [==============================] - 0s 959us/step - loss: 0.6904 - accuracy: 0.5395\n",
      "Epoch 139/150\n",
      "286/286 [==============================] - 0s 973us/step - loss: 0.6909 - accuracy: 0.5440\n",
      "Epoch 140/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.6912 - accuracy: 0.5356\n",
      "Epoch 141/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.5296\n",
      "Epoch 142/150\n",
      "286/286 [==============================] - 0s 938us/step - loss: 0.6908 - accuracy: 0.5465\n",
      "Epoch 143/150\n",
      "286/286 [==============================] - 0s 973us/step - loss: 0.6929 - accuracy: 0.5268\n",
      "Epoch 144/150\n",
      "286/286 [==============================] - 0s 955us/step - loss: 0.6920 - accuracy: 0.5331\n",
      "Epoch 145/150\n",
      "286/286 [==============================] - 0s 938us/step - loss: 0.6924 - accuracy: 0.5191\n",
      "Epoch 146/150\n",
      "286/286 [==============================] - 0s 949us/step - loss: 0.6914 - accuracy: 0.5345\n",
      "Epoch 147/150\n",
      "286/286 [==============================] - 0s 959us/step - loss: 0.6924 - accuracy: 0.5303\n",
      "Epoch 148/150\n",
      "286/286 [==============================] - 0s 969us/step - loss: 0.6903 - accuracy: 0.5430\n",
      "Epoch 149/150\n",
      "286/286 [==============================] - 0s 966us/step - loss: 0.6913 - accuracy: 0.5345\n",
      "Epoch 150/150\n",
      "286/286 [==============================] - 0s 990us/step - loss: 0.6923 - accuracy: 0.5261\n",
      " 1/44 [..............................] - ETA: 0s - loss: 0.6967 - accuracy: 0.4375WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "44/44 [==============================] - 0s 748us/step - loss: 0.6932 - accuracy: 0.4840\n"
     ]
    }
   ],
   "source": [
    "fraud = frames[frames['valid']==0][0:200]\n",
    "frames = pd.concat([nofraud, fraud])\n",
    "x = frames.iloc[:,0:4].to_numpy()\n",
    "y = frames.iloc[:,4:5]\n",
    "\n",
    "sX_resampled, sy_resampled = SMOTE().fit_resample(x, y)\n",
    "aX_resampled, ay_resampled = ADASYN().fit_resample(x, y)\n",
    "\n",
    "y = pd.get_dummies(sy_resampled.valid).to_numpy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(sX_resampled, y, test_size=0.33, random_state=42)\n",
    "\n",
    "model.fit(X_train, y_train, epochs=150, batch_size=10)\n",
    "\n",
    "_, accuracy = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ADASYN Based Neural Network with accuracy of 98%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.6906 - accuracy: 0.5337\n",
      "Epoch 2/150\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.6898 - accuracy: 0.5362\n",
      "Epoch 3/150\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.6914 - accuracy: 0.5453\n",
      "Epoch 4/150\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.6912 - accuracy: 0.5387\n",
      "Epoch 5/150\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.6900 - accuracy: 0.5439\n",
      "Epoch 6/150\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.6901 - accuracy: 0.5383\n",
      "Epoch 7/150\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.6901 - accuracy: 0.5404\n",
      "Epoch 8/150\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.5271\n",
      "Epoch 9/150\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.6906 - accuracy: 0.5327\n",
      "Epoch 10/150\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.6905 - accuracy: 0.5408\n",
      "Epoch 11/150\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5242\n",
      "Epoch 12/150\n",
      "285/285 [==============================] - 0s 973us/step - loss: 0.6896 - accuracy: 0.5457\n",
      "Epoch 13/150\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.6913 - accuracy: 0.5278\n",
      "Epoch 14/150\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5162\n",
      "Epoch 15/150\n",
      "285/285 [==============================] - 0s 952us/step - loss: 0.6919 - accuracy: 0.5327\n",
      "Epoch 16/150\n",
      "285/285 [==============================] - 0s 976us/step - loss: 0.6928 - accuracy: 0.5249\n",
      "Epoch 17/150\n",
      "285/285 [==============================] - 0s 962us/step - loss: 0.6923 - accuracy: 0.5225\n",
      "Epoch 18/150\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.6910 - accuracy: 0.5390\n",
      "Epoch 19/150\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.6906 - accuracy: 0.5355\n",
      "Epoch 20/150\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.5344\n",
      "Epoch 21/150\n",
      "285/285 [==============================] - 0s 976us/step - loss: 0.6924 - accuracy: 0.5249\n",
      "Epoch 22/150\n",
      "285/285 [==============================] - 0s 959us/step - loss: 0.6913 - accuracy: 0.5253\n",
      "Epoch 23/150\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5242\n",
      "Epoch 24/150\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.6884 - accuracy: 0.5478\n",
      "Epoch 25/150\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 0.6901 - accuracy: 0.5439\n",
      "Epoch 26/150\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.6883 - accuracy: 0.5527\n",
      "Epoch 27/150\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.6909 - accuracy: 0.5369\n",
      "Epoch 28/150\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.6912 - accuracy: 0.5379\n",
      "Epoch 29/150\n",
      "285/285 [==============================] - 0s 987us/step - loss: 0.6922 - accuracy: 0.5260\n",
      "Epoch 30/150\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.6913 - accuracy: 0.5320\n",
      "Epoch 31/150\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.6903 - accuracy: 0.5394\n",
      "Epoch 32/150\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.6901 - accuracy: 0.5432\n",
      "Epoch 33/150\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.6927 - accuracy: 0.5207\n",
      "Epoch 34/150\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.6888 - accuracy: 0.5418\n",
      "Epoch 35/150\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.6916 - accuracy: 0.5327\n",
      "Epoch 36/150\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5302\n",
      "Epoch 37/150\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.6902 - accuracy: 0.5348\n",
      "Epoch 38/150\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.6909 - accuracy: 0.5271\n",
      "Epoch 39/150\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5246\n",
      "Epoch 40/150\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.6906 - accuracy: 0.5341\n",
      "Epoch 41/150\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.6911 - accuracy: 0.5450\n",
      "Epoch 42/150\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.6892 - accuracy: 0.5411\n",
      "Epoch 43/150\n",
      "285/285 [==============================] - 0s 990us/step - loss: 0.6914 - accuracy: 0.5316\n",
      "Epoch 44/150\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.6908 - accuracy: 0.5358\n",
      "Epoch 45/150\n",
      "285/285 [==============================] - 0s 976us/step - loss: 0.6896 - accuracy: 0.5383\n",
      "Epoch 46/150\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.6908 - accuracy: 0.5429\n",
      "Epoch 47/150\n",
      "285/285 [==============================] - 0s 980us/step - loss: 0.6903 - accuracy: 0.5372\n",
      "Epoch 48/150\n",
      "285/285 [==============================] - 0s 973us/step - loss: 0.6923 - accuracy: 0.5330\n",
      "Epoch 49/150\n",
      "285/285 [==============================] - 0s 980us/step - loss: 0.6906 - accuracy: 0.5320\n",
      "Epoch 50/150\n",
      "285/285 [==============================] - 0s 966us/step - loss: 0.6900 - accuracy: 0.5432\n",
      "Epoch 51/150\n",
      "285/285 [==============================] - 0s 955us/step - loss: 0.6908 - accuracy: 0.5355\n",
      "Epoch 52/150\n",
      "285/285 [==============================] - 0s 980us/step - loss: 0.6894 - accuracy: 0.5531\n",
      "Epoch 53/150\n",
      "285/285 [==============================] - 0s 966us/step - loss: 0.6886 - accuracy: 0.5474\n",
      "Epoch 54/150\n",
      "285/285 [==============================] - 0s 983us/step - loss: 0.6900 - accuracy: 0.5460\n",
      "Epoch 55/150\n",
      "285/285 [==============================] - 0s 969us/step - loss: 0.6933 - accuracy: 0.5176\n",
      "Epoch 56/150\n",
      "285/285 [==============================] - 0s 980us/step - loss: 0.6900 - accuracy: 0.5411\n",
      "Epoch 57/150\n",
      "285/285 [==============================] - 0s 955us/step - loss: 0.6908 - accuracy: 0.5313\n",
      "Epoch 58/150\n",
      "285/285 [==============================] - 0s 959us/step - loss: 0.6909 - accuracy: 0.5418\n",
      "Epoch 59/150\n",
      "285/285 [==============================] - 0s 983us/step - loss: 0.6928 - accuracy: 0.5158\n",
      "Epoch 60/150\n",
      "285/285 [==============================] - 0s 976us/step - loss: 0.6893 - accuracy: 0.5334\n",
      "Epoch 61/150\n",
      "285/285 [==============================] - 0s 983us/step - loss: 0.6921 - accuracy: 0.5355\n",
      "Epoch 62/150\n",
      "285/285 [==============================] - 0s 962us/step - loss: 0.6884 - accuracy: 0.5425\n",
      "Epoch 63/150\n",
      "285/285 [==============================] - 0s 941us/step - loss: 0.6921 - accuracy: 0.5337\n",
      "Epoch 64/150\n",
      "285/285 [==============================] - 0s 962us/step - loss: 0.6902 - accuracy: 0.5446\n",
      "Epoch 65/150\n",
      "285/285 [==============================] - 0s 952us/step - loss: 0.6900 - accuracy: 0.5348\n",
      "Epoch 66/150\n",
      "285/285 [==============================] - 0s 980us/step - loss: 0.6904 - accuracy: 0.5436\n",
      "Epoch 67/150\n",
      "285/285 [==============================] - 0s 973us/step - loss: 0.6906 - accuracy: 0.5351\n",
      "Epoch 68/150\n",
      "285/285 [==============================] - 0s 959us/step - loss: 0.6931 - accuracy: 0.5249\n",
      "Epoch 69/150\n",
      "285/285 [==============================] - 0s 962us/step - loss: 0.6908 - accuracy: 0.5313\n",
      "Epoch 70/150\n",
      "285/285 [==============================] - 0s 959us/step - loss: 0.6912 - accuracy: 0.5327\n",
      "Epoch 71/150\n",
      "285/285 [==============================] - 0s 980us/step - loss: 0.6922 - accuracy: 0.5285\n",
      "Epoch 72/150\n",
      "285/285 [==============================] - 0s 962us/step - loss: 0.6912 - accuracy: 0.5387\n",
      "Epoch 73/150\n",
      "285/285 [==============================] - 0s 948us/step - loss: 0.6913 - accuracy: 0.5316\n",
      "Epoch 74/150\n",
      "285/285 [==============================] - 0s 948us/step - loss: 0.6913 - accuracy: 0.5390\n",
      "Epoch 75/150\n",
      "285/285 [==============================] - 0s 983us/step - loss: 0.6915 - accuracy: 0.5302\n",
      "Epoch 76/150\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.6909 - accuracy: 0.5439\n",
      "Epoch 77/150\n",
      "285/285 [==============================] - 0s 945us/step - loss: 0.6894 - accuracy: 0.5495\n",
      "Epoch 78/150\n",
      "285/285 [==============================] - 0s 962us/step - loss: 0.6919 - accuracy: 0.5235\n",
      "Epoch 79/150\n",
      "285/285 [==============================] - 0s 983us/step - loss: 0.6925 - accuracy: 0.52640s - loss: 0.6925 - accuracy: \n",
      "Epoch 80/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "285/285 [==============================] - 0s 976us/step - loss: 0.6890 - accuracy: 0.5464\n",
      "Epoch 81/150\n",
      "285/285 [==============================] - 0s 976us/step - loss: 0.6921 - accuracy: 0.5239\n",
      "Epoch 82/150\n",
      "285/285 [==============================] - 0s 966us/step - loss: 0.6928 - accuracy: 0.5242\n",
      "Epoch 83/150\n",
      "285/285 [==============================] - 0s 941us/step - loss: 0.6926 - accuracy: 0.5285\n",
      "Epoch 84/150\n",
      "285/285 [==============================] - 0s 945us/step - loss: 0.6923 - accuracy: 0.5228\n",
      "Epoch 85/150\n",
      "285/285 [==============================] - 0s 959us/step - loss: 0.6913 - accuracy: 0.53160s - loss: 0.6908 - accuracy: \n",
      "Epoch 86/150\n",
      "285/285 [==============================] - 0s 966us/step - loss: 0.6916 - accuracy: 0.5320\n",
      "Epoch 87/150\n",
      "285/285 [==============================] - 0s 948us/step - loss: 0.6918 - accuracy: 0.5320\n",
      "Epoch 88/150\n",
      "285/285 [==============================] - 0s 948us/step - loss: 0.6921 - accuracy: 0.5351\n",
      "Epoch 89/150\n",
      "285/285 [==============================] - 0s 924us/step - loss: 0.6921 - accuracy: 0.5299\n",
      "Epoch 90/150\n",
      "285/285 [==============================] - 0s 945us/step - loss: 0.6892 - accuracy: 0.5502\n",
      "Epoch 91/150\n",
      "285/285 [==============================] - 0s 955us/step - loss: 0.6902 - accuracy: 0.5401\n",
      "Epoch 92/150\n",
      "285/285 [==============================] - 0s 980us/step - loss: 0.6874 - accuracy: 0.5450\n",
      "Epoch 93/150\n",
      "285/285 [==============================] - 0s 955us/step - loss: 0.6916 - accuracy: 0.5365\n",
      "Epoch 94/150\n",
      "285/285 [==============================] - 0s 955us/step - loss: 0.6897 - accuracy: 0.5281\n",
      "Epoch 95/150\n",
      "285/285 [==============================] - 0s 962us/step - loss: 0.6908 - accuracy: 0.5232\n",
      "Epoch 96/150\n",
      "285/285 [==============================] - 0s 955us/step - loss: 0.6896 - accuracy: 0.5485\n",
      "Epoch 97/150\n",
      "285/285 [==============================] - ETA: 0s - loss: 0.6931 - accuracy: 0.52 - 0s 987us/step - loss: 0.6929 - accuracy: 0.5285\n",
      "Epoch 98/150\n",
      "285/285 [==============================] - 0s 962us/step - loss: 0.6896 - accuracy: 0.5422\n",
      "Epoch 99/150\n",
      "285/285 [==============================] - 0s 959us/step - loss: 0.6929 - accuracy: 0.5249\n",
      "Epoch 100/150\n",
      "285/285 [==============================] - 0s 948us/step - loss: 0.6911 - accuracy: 0.5415\n",
      "Epoch 101/150\n",
      "285/285 [==============================] - 0s 962us/step - loss: 0.6899 - accuracy: 0.5425\n",
      "Epoch 102/150\n",
      "285/285 [==============================] - 0s 948us/step - loss: 0.6904 - accuracy: 0.5397\n",
      "Epoch 103/150\n",
      "285/285 [==============================] - 0s 976us/step - loss: 0.6891 - accuracy: 0.5408\n",
      "Epoch 104/150\n",
      "285/285 [==============================] - 0s 941us/step - loss: 0.6907 - accuracy: 0.5383\n",
      "Epoch 105/150\n",
      "285/285 [==============================] - 0s 966us/step - loss: 0.6912 - accuracy: 0.5394\n",
      "Epoch 106/150\n",
      "285/285 [==============================] - 0s 948us/step - loss: 0.6915 - accuracy: 0.5306\n",
      "Epoch 107/150\n",
      "285/285 [==============================] - 0s 966us/step - loss: 0.6907 - accuracy: 0.5355\n",
      "Epoch 108/150\n",
      "285/285 [==============================] - 0s 969us/step - loss: 0.6926 - accuracy: 0.5211\n",
      "Epoch 109/150\n",
      "285/285 [==============================] - 0s 994us/step - loss: 0.6913 - accuracy: 0.5316\n",
      "Epoch 110/150\n",
      "285/285 [==============================] - 0s 969us/step - loss: 0.6907 - accuracy: 0.5327\n",
      "Epoch 111/150\n",
      "285/285 [==============================] - 0s 945us/step - loss: 0.6905 - accuracy: 0.5320\n",
      "Epoch 112/150\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5232\n",
      "Epoch 113/150\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.6914 - accuracy: 0.5306\n",
      "Epoch 114/150\n",
      "285/285 [==============================] - 0s 955us/step - loss: 0.6910 - accuracy: 0.5242\n",
      "Epoch 115/150\n",
      "285/285 [==============================] - 0s 941us/step - loss: 0.6886 - accuracy: 0.5492\n",
      "Epoch 116/150\n",
      "285/285 [==============================] - 0s 980us/step - loss: 0.6930 - accuracy: 0.5313\n",
      "Epoch 117/150\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.6914 - accuracy: 0.5278\n",
      "Epoch 118/150\n",
      "285/285 [==============================] - 0s 962us/step - loss: 0.6898 - accuracy: 0.5362\n",
      "Epoch 119/150\n",
      "285/285 [==============================] - 0s 948us/step - loss: 0.6900 - accuracy: 0.5355\n",
      "Epoch 120/150\n",
      "285/285 [==============================] - 0s 952us/step - loss: 0.6921 - accuracy: 0.5320\n",
      "Epoch 121/150\n",
      "285/285 [==============================] - 0s 962us/step - loss: 0.6903 - accuracy: 0.5348\n",
      "Epoch 122/150\n",
      "285/285 [==============================] - 0s 976us/step - loss: 0.6906 - accuracy: 0.5404\n",
      "Epoch 123/150\n",
      "285/285 [==============================] - 0s 976us/step - loss: 0.6888 - accuracy: 0.5411\n",
      "Epoch 124/150\n",
      "285/285 [==============================] - 0s 955us/step - loss: 0.6903 - accuracy: 0.5471\n",
      "Epoch 125/150\n",
      "285/285 [==============================] - 0s 955us/step - loss: 0.6897 - accuracy: 0.5383\n",
      "Epoch 126/150\n",
      "285/285 [==============================] - 0s 948us/step - loss: 0.6915 - accuracy: 0.5309\n",
      "Epoch 127/150\n",
      "285/285 [==============================] - 0s 959us/step - loss: 0.6895 - accuracy: 0.5422\n",
      "Epoch 128/150\n",
      "285/285 [==============================] - 0s 955us/step - loss: 0.6882 - accuracy: 0.5474\n",
      "Epoch 129/150\n",
      "285/285 [==============================] - 0s 955us/step - loss: 0.6904 - accuracy: 0.5344\n",
      "Epoch 130/150\n",
      "285/285 [==============================] - 0s 987us/step - loss: 0.6926 - accuracy: 0.5218\n",
      "Epoch 131/150\n",
      "285/285 [==============================] - 0s 983us/step - loss: 0.6916 - accuracy: 0.5397\n",
      "Epoch 132/150\n",
      "285/285 [==============================] - 0s 959us/step - loss: 0.6901 - accuracy: 0.5372\n",
      "Epoch 133/150\n",
      "285/285 [==============================] - 0s 987us/step - loss: 0.6912 - accuracy: 0.5411\n",
      "Epoch 134/150\n",
      "285/285 [==============================] - 0s 962us/step - loss: 0.6911 - accuracy: 0.5365\n",
      "Epoch 135/150\n",
      "285/285 [==============================] - 0s 990us/step - loss: 0.6880 - accuracy: 0.5453\n",
      "Epoch 136/150\n",
      "285/285 [==============================] - 0s 983us/step - loss: 0.6925 - accuracy: 0.5299\n",
      "Epoch 137/150\n",
      "285/285 [==============================] - 0s 994us/step - loss: 0.6912 - accuracy: 0.5313\n",
      "Epoch 138/150\n",
      "285/285 [==============================] - 0s 962us/step - loss: 0.6910 - accuracy: 0.5330\n",
      "Epoch 139/150\n",
      "285/285 [==============================] - 0s 987us/step - loss: 0.6907 - accuracy: 0.5376\n",
      "Epoch 140/150\n",
      "285/285 [==============================] - 0s 969us/step - loss: 0.6903 - accuracy: 0.5358\n",
      "Epoch 141/150\n",
      "285/285 [==============================] - 0s 997us/step - loss: 0.6898 - accuracy: 0.5432\n",
      "Epoch 142/150\n",
      "285/285 [==============================] - 0s 990us/step - loss: 0.6924 - accuracy: 0.5302\n",
      "Epoch 143/150\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.6913 - accuracy: 0.5288\n",
      "Epoch 144/150\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.6906 - accuracy: 0.5323\n",
      "Epoch 145/150\n",
      "285/285 [==============================] - 0s 962us/step - loss: 0.6919 - accuracy: 0.5348\n",
      "Epoch 146/150\n",
      "285/285 [==============================] - 0s 976us/step - loss: 0.6904 - accuracy: 0.5362\n",
      "Epoch 147/150\n",
      "285/285 [==============================] - 0s 966us/step - loss: 0.6905 - accuracy: 0.5387\n",
      "Epoch 148/150\n",
      "285/285 [==============================] - 0s 983us/step - loss: 0.6905 - accuracy: 0.5358\n",
      "Epoch 149/150\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.6900 - accuracy: 0.5362\n",
      "Epoch 150/150\n",
      "285/285 [==============================] - 0s 955us/step - loss: 0.6909 - accuracy: 0.5411\n",
      "44/44 [==============================] - 0s 703us/step - loss: 0.6854 - accuracy: 0.4872\n",
      "Epoch 1/150\n",
      "  1/285 [..............................] - ETA: 0s - loss: 38.6786 - accuracy: 0.8000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 17.2262 - accuracy: 0.5046\n",
      "Epoch 2/150\n",
      "285/285 [==============================] - 0s 948us/step - loss: 6.5913 - accuracy: 0.5084\n",
      "Epoch 3/150\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 3.3166 - accuracy: 0.5007\n",
      "Epoch 4/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "285/285 [==============================] - 0s 1ms/step - loss: 2.2412 - accuracy: 0.4989\n",
      "Epoch 5/150\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 1.5701 - accuracy: 0.5095\n",
      "Epoch 6/150\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 1.2955 - accuracy: 0.5021\n",
      "Epoch 7/150\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 1.1012 - accuracy: 0.5021\n",
      "Epoch 8/150\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.9328 - accuracy: 0.5063\n",
      "Epoch 9/150\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.8921 - accuracy: 0.4968\n",
      "Epoch 10/150\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.8328 - accuracy: 0.5049\n",
      "Epoch 11/150\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.7509 - accuracy: 0.5077\n",
      "Epoch 12/150\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.7365 - accuracy: 0.5032\n",
      "Epoch 13/150\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.7102 - accuracy: 0.5081\n",
      "Epoch 14/150\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.7265 - accuracy: 0.5070\n",
      "Epoch 15/150\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.7217 - accuracy: 0.5074\n",
      "Epoch 16/150\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.7112 - accuracy: 0.5039\n",
      "Epoch 17/150\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.7016 - accuracy: 0.5098\n",
      "Epoch 18/150\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.7001 - accuracy: 0.5077\n",
      "Epoch 19/150\n",
      "285/285 [==============================] - 0s 938us/step - loss: 0.7166 - accuracy: 0.5028\n",
      "Epoch 20/150\n",
      "285/285 [==============================] - 0s 938us/step - loss: 0.6910 - accuracy: 0.5014\n",
      "Epoch 21/150\n",
      "285/285 [==============================] - 0s 941us/step - loss: 0.6926 - accuracy: 0.5018\n",
      "Epoch 22/150\n",
      "285/285 [==============================] - 0s 945us/step - loss: 0.6926 - accuracy: 0.5063\n",
      "Epoch 23/150\n",
      "285/285 [==============================] - 0s 941us/step - loss: 0.6879 - accuracy: 0.5067\n",
      "Epoch 24/150\n",
      "285/285 [==============================] - 0s 955us/step - loss: 0.6991 - accuracy: 0.4947\n",
      "Epoch 25/150\n",
      "285/285 [==============================] - 0s 927us/step - loss: 0.6962 - accuracy: 0.5049\n",
      "Epoch 26/150\n",
      "285/285 [==============================] - 0s 938us/step - loss: 0.6948 - accuracy: 0.4993\n",
      "Epoch 27/150\n",
      "285/285 [==============================] - 0s 945us/step - loss: 0.6932 - accuracy: 0.5056\n",
      "Epoch 28/150\n",
      "285/285 [==============================] - 0s 945us/step - loss: 0.6906 - accuracy: 0.4993\n",
      "Epoch 29/150\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.6910 - accuracy: 0.5046\n",
      "Epoch 30/150\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.6896 - accuracy: 0.5060\n",
      "Epoch 31/150\n",
      "285/285 [==============================] - 0s 994us/step - loss: 0.6875 - accuracy: 0.4975\n",
      "Epoch 32/150\n",
      "285/285 [==============================] - 0s 969us/step - loss: 0.6870 - accuracy: 0.5035\n",
      "Epoch 33/150\n",
      "285/285 [==============================] - 0s 959us/step - loss: 0.6811 - accuracy: 0.5176\n",
      "Epoch 34/150\n",
      "285/285 [==============================] - 0s 941us/step - loss: 0.6797 - accuracy: 0.5253\n",
      "Epoch 35/150\n",
      "285/285 [==============================] - 0s 959us/step - loss: 0.6766 - accuracy: 0.5253\n",
      "Epoch 36/150\n",
      "285/285 [==============================] - 0s 945us/step - loss: 0.6808 - accuracy: 0.5351\n",
      "Epoch 37/150\n",
      "285/285 [==============================] - 0s 945us/step - loss: 0.6607 - accuracy: 0.5457\n",
      "Epoch 38/150\n",
      "285/285 [==============================] - 0s 938us/step - loss: 0.6680 - accuracy: 0.5390\n",
      "Epoch 39/150\n",
      "285/285 [==============================] - 0s 955us/step - loss: 0.6579 - accuracy: 0.5464\n",
      "Epoch 40/150\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.6579 - accuracy: 0.5502\n",
      "Epoch 41/150\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.6869 - accuracy: 0.5432\n",
      "Epoch 42/150\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.6672 - accuracy: 0.5464\n",
      "Epoch 43/150\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.6562 - accuracy: 0.5527\n",
      "Epoch 44/150\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.6656 - accuracy: 0.5590\n",
      "Epoch 45/150\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.6499 - accuracy: 0.5650\n",
      "Epoch 46/150\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.6580 - accuracy: 0.5583\n",
      "Epoch 47/150\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.6417 - accuracy: 0.5850\n",
      "Epoch 48/150\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.6562 - accuracy: 0.5931: 0s - loss: 0.6337 - accura\n",
      "Epoch 49/150\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.6388 - accuracy: 0.6008\n",
      "Epoch 50/150\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.6407 - accuracy: 0.5892\n",
      "Epoch 51/150\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.6274 - accuracy: 0.6107\n",
      "Epoch 52/150\n",
      "285/285 [==============================] - 0s 997us/step - loss: 0.6121 - accuracy: 0.6061\n",
      "Epoch 53/150\n",
      "285/285 [==============================] - ETA: 0s - loss: 0.6229 - accuracy: 0.59 - 0s 1ms/step - loss: 0.6213 - accuracy: 0.5959\n",
      "Epoch 54/150\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.6278 - accuracy: 0.6082\n",
      "Epoch 55/150\n",
      "285/285 [==============================] - 0s 976us/step - loss: 0.6141 - accuracy: 0.6103\n",
      "Epoch 56/150\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.6289 - accuracy: 0.6054\n",
      "Epoch 57/150\n",
      "285/285 [==============================] - 0s 969us/step - loss: 0.6324 - accuracy: 0.6100\n",
      "Epoch 58/150\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.6199 - accuracy: 0.6152\n",
      "Epoch 59/150\n",
      "285/285 [==============================] - 0s 966us/step - loss: 0.6130 - accuracy: 0.6082\n",
      "Epoch 60/150\n",
      "285/285 [==============================] - 0s 959us/step - loss: 0.6087 - accuracy: 0.6219\n",
      "Epoch 61/150\n",
      "285/285 [==============================] - 0s 952us/step - loss: 0.6094 - accuracy: 0.6205\n",
      "Epoch 62/150\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.6376 - accuracy: 0.6174\n",
      "Epoch 63/150\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.6329 - accuracy: 0.6223\n",
      "Epoch 64/150\n",
      "285/285 [==============================] - 0s 945us/step - loss: 0.6050 - accuracy: 0.6353\n",
      "Epoch 65/150\n",
      "285/285 [==============================] - 0s 959us/step - loss: 0.6134 - accuracy: 0.6307\n",
      "Epoch 66/150\n",
      "285/285 [==============================] - 0s 962us/step - loss: 0.6098 - accuracy: 0.6240\n",
      "Epoch 67/150\n",
      "285/285 [==============================] - 0s 941us/step - loss: 0.6061 - accuracy: 0.6297\n",
      "Epoch 68/150\n",
      "285/285 [==============================] - 0s 962us/step - loss: 0.5888 - accuracy: 0.6318\n",
      "Epoch 69/150\n",
      "285/285 [==============================] - 0s 938us/step - loss: 0.6261 - accuracy: 0.6198\n",
      "Epoch 70/150\n",
      "285/285 [==============================] - 0s 976us/step - loss: 0.6038 - accuracy: 0.6311\n",
      "Epoch 71/150\n",
      "285/285 [==============================] - 0s 962us/step - loss: 0.6005 - accuracy: 0.6272\n",
      "Epoch 72/150\n",
      "285/285 [==============================] - 0s 952us/step - loss: 0.6015 - accuracy: 0.6240\n",
      "Epoch 73/150\n",
      "285/285 [==============================] - 0s 955us/step - loss: 0.6120 - accuracy: 0.6275\n",
      "Epoch 74/150\n",
      "285/285 [==============================] - 0s 966us/step - loss: 0.5894 - accuracy: 0.6423\n",
      "Epoch 75/150\n",
      "285/285 [==============================] - 0s 969us/step - loss: 0.6103 - accuracy: 0.6275\n",
      "Epoch 76/150\n",
      "285/285 [==============================] - 0s 990us/step - loss: 0.6136 - accuracy: 0.6258\n",
      "Epoch 77/150\n",
      "285/285 [==============================] - 0s 952us/step - loss: 0.6050 - accuracy: 0.6384\n",
      "Epoch 78/150\n",
      "285/285 [==============================] - 0s 980us/step - loss: 0.5808 - accuracy: 0.6500\n",
      "Epoch 79/150\n",
      "285/285 [==============================] - 0s 987us/step - loss: 0.6203 - accuracy: 0.6423\n",
      "Epoch 80/150\n",
      "285/285 [==============================] - 0s 994us/step - loss: 0.6044 - accuracy: 0.6409\n",
      "Epoch 81/150\n",
      "285/285 [==============================] - 0s 966us/step - loss: 0.5803 - accuracy: 0.6595\n",
      "Epoch 82/150\n",
      "285/285 [==============================] - 0s 945us/step - loss: 0.5983 - accuracy: 0.6623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/150\n",
      "285/285 [==============================] - 0s 941us/step - loss: 0.6036 - accuracy: 0.6644\n",
      "Epoch 84/150\n",
      "285/285 [==============================] - 0s 941us/step - loss: 0.5758 - accuracy: 0.6687\n",
      "Epoch 85/150\n",
      "285/285 [==============================] - 0s 973us/step - loss: 0.5564 - accuracy: 0.6904\n",
      "Epoch 86/150\n",
      "285/285 [==============================] - 0s 938us/step - loss: 0.5777 - accuracy: 0.6760\n",
      "Epoch 87/150\n",
      "285/285 [==============================] - 0s 931us/step - loss: 0.5689 - accuracy: 0.7041\n",
      "Epoch 88/150\n",
      "285/285 [==============================] - 0s 917us/step - loss: 0.5742 - accuracy: 0.6824\n",
      "Epoch 89/150\n",
      "285/285 [==============================] - 0s 955us/step - loss: 0.5583 - accuracy: 0.6947\n",
      "Epoch 90/150\n",
      "285/285 [==============================] - 0s 948us/step - loss: 0.5745 - accuracy: 0.6848\n",
      "Epoch 91/150\n",
      "285/285 [==============================] - 0s 941us/step - loss: 0.5738 - accuracy: 0.6915\n",
      "Epoch 92/150\n",
      "285/285 [==============================] - 0s 927us/step - loss: 0.5786 - accuracy: 0.6936\n",
      "Epoch 93/150\n",
      "285/285 [==============================] - 0s 938us/step - loss: 0.5680 - accuracy: 0.6767\n",
      "Epoch 94/150\n",
      "285/285 [==============================] - 0s 938us/step - loss: 0.5699 - accuracy: 0.6876\n",
      "Epoch 95/150\n",
      "285/285 [==============================] - 0s 931us/step - loss: 0.5581 - accuracy: 0.6985\n",
      "Epoch 96/150\n",
      "285/285 [==============================] - 0s 931us/step - loss: 0.5672 - accuracy: 0.6862\n",
      "Epoch 97/150\n",
      "285/285 [==============================] - 0s 952us/step - loss: 0.5587 - accuracy: 0.6901\n",
      "Epoch 98/150\n",
      "285/285 [==============================] - 0s 959us/step - loss: 0.5775 - accuracy: 0.6915\n",
      "Epoch 99/150\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.5587 - accuracy: 0.6961\n",
      "Epoch 100/150\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.5624 - accuracy: 0.7143\n",
      "Epoch 101/150\n",
      "285/285 [==============================] - 0s 973us/step - loss: 0.5589 - accuracy: 0.7003\n",
      "Epoch 102/150\n",
      "285/285 [==============================] - 0s 927us/step - loss: 0.5527 - accuracy: 0.7129\n",
      "Epoch 103/150\n",
      "285/285 [==============================] - 0s 955us/step - loss: 0.5474 - accuracy: 0.7080\n",
      "Epoch 104/150\n",
      "285/285 [==============================] - 0s 931us/step - loss: 0.5663 - accuracy: 0.7080\n",
      "Epoch 105/150\n",
      "285/285 [==============================] - 0s 948us/step - loss: 0.5452 - accuracy: 0.7140\n",
      "Epoch 106/150\n",
      "285/285 [==============================] - 0s 931us/step - loss: 0.5325 - accuracy: 0.7238\n",
      "Epoch 107/150\n",
      "285/285 [==============================] - 0s 941us/step - loss: 0.5965 - accuracy: 0.7038\n",
      "Epoch 108/150\n",
      "285/285 [==============================] - 0s 931us/step - loss: 0.5680 - accuracy: 0.7066\n",
      "Epoch 109/150\n",
      "285/285 [==============================] - 0s 931us/step - loss: 0.5403 - accuracy: 0.7147\n",
      "Epoch 110/150\n",
      "285/285 [==============================] - 0s 920us/step - loss: 0.5489 - accuracy: 0.7063\n",
      "Epoch 111/150\n",
      "285/285 [==============================] - 0s 927us/step - loss: 0.5498 - accuracy: 0.7077\n",
      "Epoch 112/150\n",
      "285/285 [==============================] - 0s 931us/step - loss: 0.5383 - accuracy: 0.7235\n",
      "Epoch 113/150\n",
      "285/285 [==============================] - 0s 938us/step - loss: 0.5554 - accuracy: 0.7186\n",
      "Epoch 114/150\n",
      "285/285 [==============================] - 0s 945us/step - loss: 0.5533 - accuracy: 0.7087\n",
      "Epoch 115/150\n",
      "285/285 [==============================] - 0s 945us/step - loss: 0.5249 - accuracy: 0.7266\n",
      "Epoch 116/150\n",
      "285/285 [==============================] - 0s 931us/step - loss: 0.6047 - accuracy: 0.7150\n",
      "Epoch 117/150\n",
      "285/285 [==============================] - 0s 931us/step - loss: 0.5508 - accuracy: 0.7143\n",
      "Epoch 118/150\n",
      "285/285 [==============================] - 0s 948us/step - loss: 0.5421 - accuracy: 0.7077\n",
      "Epoch 119/150\n",
      "285/285 [==============================] - 0s 948us/step - loss: 0.5271 - accuracy: 0.7284\n",
      "Epoch 120/150\n",
      "285/285 [==============================] - 0s 941us/step - loss: 0.5357 - accuracy: 0.7330\n",
      "Epoch 121/150\n",
      "285/285 [==============================] - 0s 934us/step - loss: 0.5560 - accuracy: 0.7270\n",
      "Epoch 122/150\n",
      "285/285 [==============================] - 0s 941us/step - loss: 0.5202 - accuracy: 0.7358\n",
      "Epoch 123/150\n",
      "285/285 [==============================] - 0s 938us/step - loss: 0.5289 - accuracy: 0.7312\n",
      "Epoch 124/150\n",
      "285/285 [==============================] - 0s 938us/step - loss: 0.5620 - accuracy: 0.7280\n",
      "Epoch 125/150\n",
      "285/285 [==============================] - 0s 945us/step - loss: 0.5198 - accuracy: 0.7351\n",
      "Epoch 126/150\n",
      "285/285 [==============================] - 0s 931us/step - loss: 0.5336 - accuracy: 0.7340\n",
      "Epoch 127/150\n",
      "285/285 [==============================] - 0s 931us/step - loss: 0.5050 - accuracy: 0.7488\n",
      "Epoch 128/150\n",
      "285/285 [==============================] - 0s 969us/step - loss: 0.5367 - accuracy: 0.7284\n",
      "Epoch 129/150\n",
      "285/285 [==============================] - 0s 924us/step - loss: 0.5442 - accuracy: 0.7344\n",
      "Epoch 130/150\n",
      "285/285 [==============================] - 0s 934us/step - loss: 0.5189 - accuracy: 0.7393\n",
      "Epoch 131/150\n",
      "285/285 [==============================] - 0s 945us/step - loss: 0.5192 - accuracy: 0.7410\n",
      "Epoch 132/150\n",
      "285/285 [==============================] - 0s 941us/step - loss: 0.5252 - accuracy: 0.7386\n",
      "Epoch 133/150\n",
      "285/285 [==============================] - 0s 934us/step - loss: 0.5233 - accuracy: 0.7396\n",
      "Epoch 134/150\n",
      "285/285 [==============================] - 0s 955us/step - loss: 0.5371 - accuracy: 0.7266\n",
      "Epoch 135/150\n",
      "285/285 [==============================] - 0s 941us/step - loss: 0.5197 - accuracy: 0.7449\n",
      "Epoch 136/150\n",
      "285/285 [==============================] - 0s 987us/step - loss: 0.5360 - accuracy: 0.7393\n",
      "Epoch 137/150\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.5099 - accuracy: 0.7446\n",
      "Epoch 138/150\n",
      "285/285 [==============================] - 0s 934us/step - loss: 0.5205 - accuracy: 0.7477\n",
      "Epoch 139/150\n",
      "285/285 [==============================] - 0s 920us/step - loss: 0.5301 - accuracy: 0.7456\n",
      "Epoch 140/150\n",
      "285/285 [==============================] - 0s 927us/step - loss: 0.5156 - accuracy: 0.7431\n",
      "Epoch 141/150\n",
      "285/285 [==============================] - 0s 938us/step - loss: 0.5155 - accuracy: 0.7375\n",
      "Epoch 142/150\n",
      "285/285 [==============================] - 0s 959us/step - loss: 0.5569 - accuracy: 0.7330\n",
      "Epoch 143/150\n",
      "285/285 [==============================] - 0s 934us/step - loss: 0.5282 - accuracy: 0.7477\n",
      "Epoch 144/150\n",
      "285/285 [==============================] - 0s 952us/step - loss: 0.5155 - accuracy: 0.7442\n",
      "Epoch 145/150\n",
      "285/285 [==============================] - 0s 962us/step - loss: 0.5247 - accuracy: 0.7428\n",
      "Epoch 146/150\n",
      "285/285 [==============================] - 0s 938us/step - loss: 0.5391 - accuracy: 0.7477\n",
      "Epoch 147/150\n",
      "285/285 [==============================] - 0s 948us/step - loss: 0.5168 - accuracy: 0.7442\n",
      "Epoch 148/150\n",
      "285/285 [==============================] - 0s 927us/step - loss: 0.5339 - accuracy: 0.7361\n",
      "Epoch 149/150\n",
      "285/285 [==============================] - 0s 969us/step - loss: 0.5376 - accuracy: 0.7407\n",
      "Epoch 150/150\n",
      "285/285 [==============================] - 0s 952us/step - loss: 0.5492 - accuracy: 0.7277\n",
      "44/44 [==============================] - 0s 725us/step - loss: 0.2862 - accuracy: 0.9822\n",
      "Accuracy: 98.22\n"
     ]
    }
   ],
   "source": [
    "with open(\"frames.bin\", \"rb\") as f:\n",
    "    df = pickle.load(f) \n",
    "\n",
    "df = df[df['lon'] != 0]\n",
    "fraud = df[df['valid'] == 0]\n",
    "nofraud = df[df['valid'] == 1]\n",
    "\n",
    "frames = pd.concat([nofraud, fraud])\n",
    "x = frames.iloc[:,0:4].to_numpy()\n",
    "y = frames.iloc[:,4:5]\n",
    "\n",
    "sX_resampled, sy_resampled = SMOTE().fit_resample(x, y)\n",
    "aX_resampled, ay_resampled = ADASYN().fit_resample(x, y)\n",
    "\n",
    "y = pd.get_dummies(ay_resampled.valid).to_numpy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(aX_resampled, y, test_size=0.33, random_state=42)\n",
    "\n",
    "model.fit(X_train, y_train, epochs=150, batch_size=10)\n",
    "\n",
    "_, accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=4, activation='relu'))\n",
    "model.add(Dropout(0.7))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dropout(0.7))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dropout(0.7))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dropout(0.7))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=150, batch_size=10)\n",
    "\n",
    "_, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ADASYN Based neural network with 500 fraud records,  test accuracy of 98%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5203 - accuracy: 0.7334\n",
      "Epoch 2/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5287 - accuracy: 0.7390\n",
      "Epoch 3/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5555 - accuracy: 0.7390\n",
      "Epoch 4/150\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.5458 - accuracy: 0.7261\n",
      "Epoch 5/150\n",
      "286/286 [==============================] - 0s 959us/step - loss: 0.5321 - accuracy: 0.7383\n",
      "Epoch 6/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5398 - accuracy: 0.7341\n",
      "Epoch 7/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5128 - accuracy: 0.7450\n",
      "Epoch 8/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5109 - accuracy: 0.7478\n",
      "Epoch 9/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.4973 - accuracy: 0.7468\n",
      "Epoch 10/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5275 - accuracy: 0.7443\n",
      "Epoch 11/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5211 - accuracy: 0.7366\n",
      "Epoch 12/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5255 - accuracy: 0.7510\n",
      "Epoch 13/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5362 - accuracy: 0.7506\n",
      "Epoch 14/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5016 - accuracy: 0.7510\n",
      "Epoch 15/150\n",
      "286/286 [==============================] - 0s 858us/step - loss: 0.5354 - accuracy: 0.7411\n",
      "Epoch 16/150\n",
      "286/286 [==============================] - 0s 962us/step - loss: 0.5229 - accuracy: 0.7411\n",
      "Epoch 17/150\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.5263 - accuracy: 0.7436\n",
      "Epoch 18/150\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.5371 - accuracy: 0.7369\n",
      "Epoch 19/150\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.5115 - accuracy: 0.7517\n",
      "Epoch 20/150\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.5257 - accuracy: 0.7359\n",
      "Epoch 21/150\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.5311 - accuracy: 0.7429\n",
      "Epoch 22/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5214 - accuracy: 0.7390\n",
      "Epoch 23/150\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.5150 - accuracy: 0.7443\n",
      "Epoch 24/150\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.5170 - accuracy: 0.7394\n",
      "Epoch 25/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5167 - accuracy: 0.7468\n",
      "Epoch 26/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5209 - accuracy: 0.7401\n",
      "Epoch 27/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5137 - accuracy: 0.7359\n",
      "Epoch 28/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5365 - accuracy: 0.7352\n",
      "Epoch 29/150\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.5008 - accuracy: 0.7510\n",
      "Epoch 30/150\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.5300 - accuracy: 0.7394\n",
      "Epoch 31/150\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.5011 - accuracy: 0.7513\n",
      "Epoch 32/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.6027 - accuracy: 0.7162\n",
      "Epoch 33/150\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.4983 - accuracy: 0.7425\n",
      "Epoch 34/150\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.5293 - accuracy: 0.7331\n",
      "Epoch 35/150\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.5033 - accuracy: 0.7415\n",
      "Epoch 36/150\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.5451 - accuracy: 0.7390\n",
      "Epoch 37/150\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.5601 - accuracy: 0.7380\n",
      "Epoch 38/150\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.5326 - accuracy: 0.7390\n",
      "Epoch 39/150\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.5572 - accuracy: 0.73 - 1s 2ms/step - loss: 0.5552 - accuracy: 0.7313\n",
      "Epoch 40/150\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.5069 - accuracy: 0.7447\n",
      "Epoch 41/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5209 - accuracy: 0.7439\n",
      "Epoch 42/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5356 - accuracy: 0.7373\n",
      "Epoch 43/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5295 - accuracy: 0.7415\n",
      "Epoch 44/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5283 - accuracy: 0.7439\n",
      "Epoch 45/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5182 - accuracy: 0.7457\n",
      "Epoch 46/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.4910 - accuracy: 0.7545: 0s - loss: 0.4794 - accuracy\n",
      "Epoch 47/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5219 - accuracy: 0.7447\n",
      "Epoch 48/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5139 - accuracy: 0.7432\n",
      "Epoch 49/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5181 - accuracy: 0.7408\n",
      "Epoch 50/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5118 - accuracy: 0.7457\n",
      "Epoch 51/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5044 - accuracy: 0.7439\n",
      "Epoch 52/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5197 - accuracy: 0.7429\n",
      "Epoch 53/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5056 - accuracy: 0.7517\n",
      "Epoch 54/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5116 - accuracy: 0.7366\n",
      "Epoch 55/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5047 - accuracy: 0.7517\n",
      "Epoch 56/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5297 - accuracy: 0.7478\n",
      "Epoch 57/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5027 - accuracy: 0.7538\n",
      "Epoch 58/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5210 - accuracy: 0.7296\n",
      "Epoch 59/150\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7562\n",
      "Epoch 60/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5371 - accuracy: 0.7306\n",
      "Epoch 61/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5254 - accuracy: 0.7359\n",
      "Epoch 62/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5264 - accuracy: 0.7397\n",
      "Epoch 63/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5178 - accuracy: 0.7373\n",
      "Epoch 64/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5120 - accuracy: 0.7443\n",
      "Epoch 65/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5097 - accuracy: 0.7432\n",
      "Epoch 66/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5172 - accuracy: 0.7443\n",
      "Epoch 67/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5233 - accuracy: 0.7408\n",
      "Epoch 68/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.4969 - accuracy: 0.7590\n",
      "Epoch 69/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5277 - accuracy: 0.7327\n",
      "Epoch 70/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5360 - accuracy: 0.7271\n",
      "Epoch 71/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5266 - accuracy: 0.7366\n",
      "Epoch 72/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5190 - accuracy: 0.7341\n",
      "Epoch 73/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5562 - accuracy: 0.7310\n",
      "Epoch 74/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5368 - accuracy: 0.7355\n",
      "Epoch 75/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.4970 - accuracy: 0.7499\n",
      "Epoch 76/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5097 - accuracy: 0.7436\n",
      "Epoch 77/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5477 - accuracy: 0.7334\n",
      "Epoch 78/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.4901 - accuracy: 0.7524\n",
      "Epoch 79/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5293 - accuracy: 0.7464\n",
      "Epoch 80/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5545 - accuracy: 0.7306\n",
      "Epoch 81/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.4986 - accuracy: 0.7404\n",
      "Epoch 82/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5144 - accuracy: 0.7454\n",
      "Epoch 83/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5300 - accuracy: 0.7503\n",
      "Epoch 84/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5292 - accuracy: 0.7387\n",
      "Epoch 85/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5218 - accuracy: 0.7422\n",
      "Epoch 86/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5529 - accuracy: 0.7194\n",
      "Epoch 87/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5602 - accuracy: 0.7366\n",
      "Epoch 88/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5400 - accuracy: 0.7376\n",
      "Epoch 89/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5040 - accuracy: 0.7373\n",
      "Epoch 90/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5258 - accuracy: 0.7415\n",
      "Epoch 91/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5228 - accuracy: 0.7457\n",
      "Epoch 92/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5118 - accuracy: 0.7538\n",
      "Epoch 93/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5158 - accuracy: 0.7348\n",
      "Epoch 94/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5397 - accuracy: 0.7320\n",
      "Epoch 95/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5032 - accuracy: 0.7411\n",
      "Epoch 96/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5431 - accuracy: 0.7447\n",
      "Epoch 97/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5326 - accuracy: 0.7380\n",
      "Epoch 98/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5214 - accuracy: 0.7436\n",
      "Epoch 99/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5326 - accuracy: 0.7362\n",
      "Epoch 100/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5555 - accuracy: 0.7250\n",
      "Epoch 101/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5439 - accuracy: 0.7359\n",
      "Epoch 102/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5144 - accuracy: 0.7320\n",
      "Epoch 103/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5015 - accuracy: 0.7492\n",
      "Epoch 104/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.4993 - accuracy: 0.7510\n",
      "Epoch 105/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5172 - accuracy: 0.7503\n",
      "Epoch 106/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5194 - accuracy: 0.7341\n",
      "Epoch 107/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5234 - accuracy: 0.7432\n",
      "Epoch 108/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5283 - accuracy: 0.7366\n",
      "Epoch 109/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5394 - accuracy: 0.7306\n",
      "Epoch 110/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5392 - accuracy: 0.7362\n",
      "Epoch 111/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.4962 - accuracy: 0.7580\n",
      "Epoch 112/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5184 - accuracy: 0.7387\n",
      "Epoch 113/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5238 - accuracy: 0.7408\n",
      "Epoch 114/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5044 - accuracy: 0.7404\n",
      "Epoch 115/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5237 - accuracy: 0.7454\n",
      "Epoch 116/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5264 - accuracy: 0.7261\n",
      "Epoch 117/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5069 - accuracy: 0.7489\n",
      "Epoch 118/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5312 - accuracy: 0.7439\n",
      "Epoch 119/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5419 - accuracy: 0.7334\n",
      "Epoch 120/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5441 - accuracy: 0.7418\n",
      "Epoch 121/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5242 - accuracy: 0.7436\n",
      "Epoch 122/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5336 - accuracy: 0.7418\n",
      "Epoch 123/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5019 - accuracy: 0.7464\n",
      "Epoch 124/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.4956 - accuracy: 0.7534\n",
      "Epoch 125/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5225 - accuracy: 0.7282\n",
      "Epoch 126/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5176 - accuracy: 0.7475\n",
      "Epoch 127/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5001 - accuracy: 0.7517\n",
      "Epoch 128/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5583 - accuracy: 0.7219\n",
      "Epoch 129/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5178 - accuracy: 0.7404\n",
      "Epoch 130/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5088 - accuracy: 0.7454\n",
      "Epoch 131/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5091 - accuracy: 0.7401\n",
      "Epoch 132/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5267 - accuracy: 0.7373\n",
      "Epoch 133/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5426 - accuracy: 0.7454\n",
      "Epoch 134/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5295 - accuracy: 0.7383\n",
      "Epoch 135/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5266 - accuracy: 0.7282\n",
      "Epoch 136/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5059 - accuracy: 0.7468\n",
      "Epoch 137/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5252 - accuracy: 0.7482\n",
      "Epoch 138/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5187 - accuracy: 0.7331\n",
      "Epoch 139/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5526 - accuracy: 0.7271\n",
      "Epoch 140/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5310 - accuracy: 0.7366\n",
      "Epoch 141/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5391 - accuracy: 0.7352\n",
      "Epoch 142/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5355 - accuracy: 0.7411\n",
      "Epoch 143/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5143 - accuracy: 0.7580\n",
      "Epoch 144/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5120 - accuracy: 0.7429\n",
      "Epoch 145/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5241 - accuracy: 0.7404\n",
      "Epoch 146/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5152 - accuracy: 0.7390\n",
      "Epoch 147/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5594 - accuracy: 0.7338\n",
      "Epoch 148/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.4991 - accuracy: 0.7468\n",
      "Epoch 149/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5208 - accuracy: 0.7418\n",
      "Epoch 150/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5454 - accuracy: 0.7285\n",
      "44/44 [==============================] - 0s 748us/step - loss: 0.2982 - accuracy: 0.9879\n",
      "Accuracy: 98.79\n"
     ]
    }
   ],
   "source": [
    "fraud = frames[frames['valid']==0][:500]\n",
    "frames = pd.concat([nofraud, fraud])\n",
    "x = frames.iloc[:,0:4].to_numpy()\n",
    "y = frames.iloc[:,4:5]\n",
    "\n",
    "sX_resampled, sy_resampled = SMOTE().fit_resample(x, y)\n",
    "aX_resampled, ay_resampled = ADASYN().fit_resample(x, y)\n",
    "\n",
    "y = pd.get_dummies(sy_resampled.valid).to_numpy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(sX_resampled, y, test_size=0.33, random_state=42)\n",
    "\n",
    "model.fit(X_train, y_train, epochs=150, batch_size=10)\n",
    "\n",
    "_, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ADASYN Based Neural network with 200 fraud records, 98% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5401 - accuracy: 0.7355\n",
      "Epoch 2/150\n",
      "286/286 [==============================] - 0s 987us/step - loss: 0.5139 - accuracy: 0.7496\n",
      "Epoch 3/150\n",
      "286/286 [==============================] - 0s 994us/step - loss: 0.5243 - accuracy: 0.7282\n",
      "Epoch 4/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5169 - accuracy: 0.7418\n",
      "Epoch 5/150\n",
      "286/286 [==============================] - 0s 990us/step - loss: 0.5293 - accuracy: 0.7450\n",
      "Epoch 6/150\n",
      "286/286 [==============================] - 0s 994us/step - loss: 0.5154 - accuracy: 0.7387\n",
      "Epoch 7/150\n",
      "286/286 [==============================] - 0s 983us/step - loss: 0.5777 - accuracy: 0.7296\n",
      "Epoch 8/150\n",
      "286/286 [==============================] - 0s 973us/step - loss: 0.5374 - accuracy: 0.7380\n",
      "Epoch 9/150\n",
      "286/286 [==============================] - 0s 938us/step - loss: 0.5323 - accuracy: 0.7296\n",
      "Epoch 10/150\n",
      "286/286 [==============================] - 0s 935us/step - loss: 0.5192 - accuracy: 0.7447\n",
      "Epoch 11/150\n",
      "286/286 [==============================] - 0s 924us/step - loss: 0.5363 - accuracy: 0.7457\n",
      "Epoch 12/150\n",
      "286/286 [==============================] - 0s 924us/step - loss: 0.5357 - accuracy: 0.7450\n",
      "Epoch 13/150\n",
      "286/286 [==============================] - 0s 924us/step - loss: 0.5410 - accuracy: 0.7482\n",
      "Epoch 14/150\n",
      "286/286 [==============================] - 0s 966us/step - loss: 0.5186 - accuracy: 0.7415\n",
      "Epoch 15/150\n",
      "286/286 [==============================] - 0s 945us/step - loss: 0.5203 - accuracy: 0.74390s - loss: 0.5289 - accura\n",
      "Epoch 16/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5121 - accuracy: 0.7422\n",
      "Epoch 17/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5353 - accuracy: 0.7397\n",
      "Epoch 18/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5359 - accuracy: 0.7454\n",
      "Epoch 19/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5346 - accuracy: 0.7429\n",
      "Epoch 20/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5386 - accuracy: 0.7478\n",
      "Epoch 21/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5308 - accuracy: 0.7439\n",
      "Epoch 22/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5583 - accuracy: 0.7306\n",
      "Epoch 23/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5111 - accuracy: 0.7439\n",
      "Epoch 24/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5121 - accuracy: 0.7411\n",
      "Epoch 25/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5203 - accuracy: 0.7468\n",
      "Epoch 26/150\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.5152 - accuracy: 0.7436\n",
      "Epoch 27/150\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.5058 - accuracy: 0.7447\n",
      "Epoch 28/150\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.5139 - accuracy: 0.7345\n",
      "Epoch 29/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5672 - accuracy: 0.7289\n",
      "Epoch 30/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5346 - accuracy: 0.7376\n",
      "Epoch 31/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5404 - accuracy: 0.7390\n",
      "Epoch 32/150\n",
      "286/286 [==============================] - 0s 882us/step - loss: 0.5284 - accuracy: 0.7397\n",
      "Epoch 33/150\n",
      "286/286 [==============================] - 0s 872us/step - loss: 0.5052 - accuracy: 0.7489\n",
      "Epoch 34/150\n",
      "286/286 [==============================] - 0s 879us/step - loss: 0.5724 - accuracy: 0.7352\n",
      "Epoch 35/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5425 - accuracy: 0.7359\n",
      "Epoch 36/150\n",
      "286/286 [==============================] - 0s 928us/step - loss: 0.5529 - accuracy: 0.7331\n",
      "Epoch 37/150\n",
      "286/286 [==============================] - 0s 889us/step - loss: 0.5194 - accuracy: 0.7411\n",
      "Epoch 38/150\n",
      "286/286 [==============================] - 0s 945us/step - loss: 0.5082 - accuracy: 0.7461\n",
      "Epoch 39/150\n",
      "286/286 [==============================] - 0s 952us/step - loss: 0.5133 - accuracy: 0.7503\n",
      "Epoch 40/150\n",
      "286/286 [==============================] - 0s 980us/step - loss: 0.5098 - accuracy: 0.7443\n",
      "Epoch 41/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5456 - accuracy: 0.7390\n",
      "Epoch 42/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5177 - accuracy: 0.7499\n",
      "Epoch 43/150\n",
      "286/286 [==============================] - 0s 875us/step - loss: 0.5271 - accuracy: 0.7397\n",
      "Epoch 44/150\n",
      "286/286 [==============================] - 0s 910us/step - loss: 0.5575 - accuracy: 0.7390\n",
      "Epoch 45/150\n",
      "286/286 [==============================] - 0s 973us/step - loss: 0.5152 - accuracy: 0.7439\n",
      "Epoch 46/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5321 - accuracy: 0.7359\n",
      "Epoch 47/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5343 - accuracy: 0.7468\n",
      "Epoch 48/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5110 - accuracy: 0.7439\n",
      "Epoch 49/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.4965 - accuracy: 0.7513\n",
      "Epoch 50/150\n",
      "286/286 [==============================] - 0s 945us/step - loss: 0.5426 - accuracy: 0.7243\n",
      "Epoch 51/150\n",
      "286/286 [==============================] - 0s 931us/step - loss: 0.5328 - accuracy: 0.7401\n",
      "Epoch 52/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5348 - accuracy: 0.7331\n",
      "Epoch 53/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5434 - accuracy: 0.7397\n",
      "Epoch 54/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5331 - accuracy: 0.7380\n",
      "Epoch 55/150\n",
      "286/286 [==============================] - 0s 945us/step - loss: 0.5006 - accuracy: 0.7457\n",
      "Epoch 56/150\n",
      "286/286 [==============================] - 0s 896us/step - loss: 0.5236 - accuracy: 0.7503\n",
      "Epoch 57/150\n",
      "286/286 [==============================] - 0s 931us/step - loss: 0.5205 - accuracy: 0.7513\n",
      "Epoch 58/150\n",
      "286/286 [==============================] - 0s 865us/step - loss: 0.5092 - accuracy: 0.7492\n",
      "Epoch 59/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5235 - accuracy: 0.7450\n",
      "Epoch 60/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5096 - accuracy: 0.7496\n",
      "Epoch 61/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5342 - accuracy: 0.7296\n",
      "Epoch 62/150\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.5321 - accuracy: 0.7425\n",
      "Epoch 63/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5129 - accuracy: 0.7443\n",
      "Epoch 64/150\n",
      "286/286 [==============================] - 0s 973us/step - loss: 0.5358 - accuracy: 0.7352\n",
      "Epoch 65/150\n",
      "286/286 [==============================] - 0s 987us/step - loss: 0.5386 - accuracy: 0.7461\n",
      "Epoch 66/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5203 - accuracy: 0.7380\n",
      "Epoch 67/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5599 - accuracy: 0.7306\n",
      "Epoch 68/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5345 - accuracy: 0.7397\n",
      "Epoch 69/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5306 - accuracy: 0.7492: 0s - loss: 0.5149 - accura\n",
      "Epoch 70/150\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.4959 - accuracy: 0.7576\n",
      "Epoch 71/150\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.7418\n",
      "Epoch 72/150\n",
      "286/286 [==============================] - 0s 875us/step - loss: 0.5220 - accuracy: 0.7464\n",
      "Epoch 73/150\n",
      "286/286 [==============================] - 0s 900us/step - loss: 0.5826 - accuracy: 0.7233\n",
      "Epoch 74/150\n",
      "286/286 [==============================] - 0s 966us/step - loss: 0.5117 - accuracy: 0.7527\n",
      "Epoch 75/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5534 - accuracy: 0.7355\n",
      "Epoch 76/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5104 - accuracy: 0.7411\n",
      "Epoch 77/150\n",
      "286/286 [==============================] - 0s 976us/step - loss: 0.5247 - accuracy: 0.7485\n",
      "Epoch 78/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5157 - accuracy: 0.7478\n",
      "Epoch 79/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5274 - accuracy: 0.7450\n",
      "Epoch 80/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "286/286 [==============================] - 0s 959us/step - loss: 0.5175 - accuracy: 0.7432\n",
      "Epoch 81/150\n",
      "286/286 [==============================] - 0s 997us/step - loss: 0.5369 - accuracy: 0.7376\n",
      "Epoch 82/150\n",
      "286/286 [==============================] - 0s 896us/step - loss: 0.5118 - accuracy: 0.7408\n",
      "Epoch 83/150\n",
      "286/286 [==============================] - 0s 928us/step - loss: 0.5219 - accuracy: 0.7345\n",
      "Epoch 84/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5362 - accuracy: 0.7408\n",
      "Epoch 85/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5454 - accuracy: 0.7247\n",
      "Epoch 86/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5289 - accuracy: 0.7418\n",
      "Epoch 87/150\n",
      "286/286 [==============================] - 0s 931us/step - loss: 0.5526 - accuracy: 0.7425\n",
      "Epoch 88/150\n",
      "286/286 [==============================] - 0s 966us/step - loss: 0.5407 - accuracy: 0.7289\n",
      "Epoch 89/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5464 - accuracy: 0.7397\n",
      "Epoch 90/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5443 - accuracy: 0.7418\n",
      "Epoch 91/150\n",
      "286/286 [==============================] - 0s 997us/step - loss: 0.5082 - accuracy: 0.7478\n",
      "Epoch 92/150\n",
      "286/286 [==============================] - 0s 980us/step - loss: 0.5460 - accuracy: 0.7327\n",
      "Epoch 93/150\n",
      "286/286 [==============================] - 0s 955us/step - loss: 0.5224 - accuracy: 0.7411\n",
      "Epoch 94/150\n",
      "286/286 [==============================] - 0s 938us/step - loss: 0.5742 - accuracy: 0.7313\n",
      "Epoch 95/150\n",
      "286/286 [==============================] - 0s 962us/step - loss: 0.5376 - accuracy: 0.7292\n",
      "Epoch 96/150\n",
      "286/286 [==============================] - 0s 865us/step - loss: 0.5118 - accuracy: 0.7471\n",
      "Epoch 97/150\n",
      "286/286 [==============================] - 0s 983us/step - loss: 0.5275 - accuracy: 0.7461\n",
      "Epoch 98/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5431 - accuracy: 0.7355\n",
      "Epoch 99/150\n",
      "286/286 [==============================] - 0s 921us/step - loss: 0.5287 - accuracy: 0.7454\n",
      "Epoch 100/150\n",
      "286/286 [==============================] - 0s 921us/step - loss: 0.5108 - accuracy: 0.7401\n",
      "Epoch 101/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5370 - accuracy: 0.7366\n",
      "Epoch 102/150\n",
      "286/286 [==============================] - 0s 966us/step - loss: 0.5361 - accuracy: 0.7429\n",
      "Epoch 103/150\n",
      "286/286 [==============================] - 0s 868us/step - loss: 0.5087 - accuracy: 0.7366\n",
      "Epoch 104/150\n",
      "286/286 [==============================] - 0s 868us/step - loss: 0.5207 - accuracy: 0.7411\n",
      "Epoch 105/150\n",
      "286/286 [==============================] - 0s 882us/step - loss: 0.5320 - accuracy: 0.7355\n",
      "Epoch 106/150\n",
      "286/286 [==============================] - 0s 861us/step - loss: 0.4988 - accuracy: 0.7404\n",
      "Epoch 107/150\n",
      "286/286 [==============================] - 0s 886us/step - loss: 0.5402 - accuracy: 0.7341\n",
      "Epoch 108/150\n",
      "286/286 [==============================] - 0s 865us/step - loss: 0.5385 - accuracy: 0.7369\n",
      "Epoch 109/150\n",
      "286/286 [==============================] - 0s 896us/step - loss: 0.5198 - accuracy: 0.7373\n",
      "Epoch 110/150\n",
      "286/286 [==============================] - 0s 931us/step - loss: 0.5419 - accuracy: 0.7489\n",
      "Epoch 111/150\n",
      "286/286 [==============================] - 0s 907us/step - loss: 0.5388 - accuracy: 0.7299\n",
      "Epoch 112/150\n",
      "286/286 [==============================] - 0s 959us/step - loss: 0.5190 - accuracy: 0.7429\n",
      "Epoch 113/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5570 - accuracy: 0.7345\n",
      "Epoch 114/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5121 - accuracy: 0.7510\n",
      "Epoch 115/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5705 - accuracy: 0.7254\n",
      "Epoch 116/150\n",
      "286/286 [==============================] - 0s 938us/step - loss: 0.5186 - accuracy: 0.7380\n",
      "Epoch 117/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5270 - accuracy: 0.7454\n",
      "Epoch 118/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5383 - accuracy: 0.7425\n",
      "Epoch 119/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5183 - accuracy: 0.7415\n",
      "Epoch 120/150\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.5253 - accuracy: 0.7499\n",
      "Epoch 121/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5229 - accuracy: 0.7555\n",
      "Epoch 122/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5377 - accuracy: 0.7369\n",
      "Epoch 123/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5504 - accuracy: 0.7254\n",
      "Epoch 124/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5139 - accuracy: 0.7538\n",
      "Epoch 125/150\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.5163 - accuracy: 0.7527\n",
      "Epoch 126/150\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.5154 - accuracy: 0.7432\n",
      "Epoch 127/150\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.5155 - accuracy: 0.7404: 0s - loss: 0.5390 - \n",
      "Epoch 128/150\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.5015 - accuracy: 0.7513\n",
      "Epoch 129/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5314 - accuracy: 0.7397\n",
      "Epoch 130/150\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.5306 - accuracy: 0.7320\n",
      "Epoch 131/150\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.5160 - accuracy: 0.7401\n",
      "Epoch 132/150\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.5590 - accuracy: 0.7429\n",
      "Epoch 133/150\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.5118 - accuracy: 0.7447\n",
      "Epoch 134/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5202 - accuracy: 0.7331\n",
      "Epoch 135/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5134 - accuracy: 0.7471\n",
      "Epoch 136/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5308 - accuracy: 0.7352\n",
      "Epoch 137/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5733 - accuracy: 0.7369\n",
      "Epoch 138/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5043 - accuracy: 0.7489\n",
      "Epoch 139/150\n",
      "286/286 [==============================] - 0s 959us/step - loss: 0.5239 - accuracy: 0.7499\n",
      "Epoch 140/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5060 - accuracy: 0.7429\n",
      "Epoch 141/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5347 - accuracy: 0.7313\n",
      "Epoch 142/150\n",
      "286/286 [==============================] - 0s 987us/step - loss: 0.5192 - accuracy: 0.7471\n",
      "Epoch 143/150\n",
      "286/286 [==============================] - 0s 872us/step - loss: 0.5240 - accuracy: 0.7404\n",
      "Epoch 144/150\n",
      "286/286 [==============================] - 0s 875us/step - loss: 0.5092 - accuracy: 0.7366\n",
      "Epoch 145/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5405 - accuracy: 0.7369\n",
      "Epoch 146/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5108 - accuracy: 0.7506\n",
      "Epoch 147/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5106 - accuracy: 0.7443\n",
      "Epoch 148/150\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.5247 - accuracy: 0.7383\n",
      "Epoch 149/150\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.5274 - accuracy: 0.7457\n",
      "Epoch 150/150\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.5272 - accuracy: 0.7397\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.2708 - accuracy: 0.9865\n",
      "Accuracy: 98.65\n"
     ]
    }
   ],
   "source": [
    "fraud = frames[frames['valid']==0][:200]\n",
    "frames = pd.concat([nofraud, fraud])\n",
    "x = frames.iloc[:,0:4].to_numpy()\n",
    "y = frames.iloc[:,4:5]\n",
    "\n",
    "sX_resampled, sy_resampled = SMOTE().fit_resample(x, y)\n",
    "aX_resampled, ay_resampled = ADASYN().fit_resample(x, y)\n",
    "\n",
    "y = pd.get_dummies(sy_resampled.valid).to_numpy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(sX_resampled, y, test_size=0.33, random_state=42)\n",
    "\n",
    "model.fit(X_train, y_train, epochs=150, batch_size=10)\n",
    "\n",
    "_, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression with SMOTE Sampling, accuracy 93%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9378480632161711"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"frames.bin\", \"rb\") as f:\n",
    "    df = pickle.load(f) \n",
    "\n",
    "df = df[df['lon'] != 0]\n",
    "fraud = df[df['valid'] == 0]\n",
    "nofraud = df[df['valid'] == 1]\n",
    "\n",
    "frames = pd.concat([nofraud, fraud])\n",
    "x = frames.iloc[:,0:4].to_numpy()\n",
    "y = frames.iloc[:,4:5]\n",
    "sX_resampled, sy_resampled = SMOTE().fit_resample(x, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(sX_resampled, sy_resampled, test_size=0.33, random_state=42)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "reg = LinearRegression().fit(X_train, y_train)\n",
    "reg.score(X_test,y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression with ADASYN, 92% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.927158332046335"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"frames.bin\", \"rb\") as f:\n",
    "    df = pickle.load(f) \n",
    "\n",
    "df = df[df['lon'] != 0]\n",
    "fraud = df[df['valid'] == 0]\n",
    "nofraud = df[df['valid'] == 1]\n",
    "\n",
    "frames = pd.concat([nofraud, fraud])\n",
    "x = frames.iloc[:,0:4].to_numpy()\n",
    "y = frames.iloc[:,4:5]\n",
    "aX_resampled, ay_resampled = ADASYN().fit_resample(x, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(aX_resampled, ay_resampled, test_size=0.33, random_state=42)\n",
    "\n",
    "\n",
    "reg = LinearRegression().fit(X_train, y_train)\n",
    "reg.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
